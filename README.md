# WaggleBot ğŸ¤–

> ì»¤ë®¤ë‹ˆí‹° ì¸ê¸° ê²Œì‹œê¸€ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ ìœ íŠœë¸Œ ì‡¼ì¸  ì˜ìƒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” AI íŒŒì´í”„ë¼ì¸

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![GPU](https://img.shields.io/badge/GPU-NVIDIA%20RTX%203080%20Ti-76B900.svg)](https://www.nvidia.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

WaggleBotì€ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ê³ , LLMìœ¼ë¡œ ìš”ì•½í•œ ë’¤, TTSì™€ FFmpegë¥¼ ì´ìš©í•´ ì‡¼ì¸  ì˜ìƒ(9:16)ì„ ìë™ ìƒì„±í•˜ëŠ” ì™„ì „ ìë™í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- ğŸ•·ï¸ **ìë™ í¬ë¡¤ë§**: ë„¤ì´íŠ¸íŒ ë“± ì»¤ë®¤ë‹ˆí‹° ì‚¬ì´íŠ¸ì—ì„œ ì¸ê¸° ê²Œì‹œê¸€ ìˆ˜ì§‘
- ğŸ§  **AI ìš”ì•½**: ë¡œì»¬ LLMì„ ì‚¬ìš©í•œ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„± (200ì ì´ë‚´)
- ğŸ™ï¸ **TTS ìŒì„± í•©ì„±**: Kokoro-82M, GPT-SoVITS, Edge-TTS ì§€ì›
- ğŸ¬ **ì˜ìƒ ë Œë”ë§**: FFmpeg + NVENC GPU ê°€ì† (20ë°° ë¹ ë¥¸ ì¸ì½”ë”©)
- ğŸ“Š **ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ**: Streamlit ê¸°ë°˜ ì›¹ UIë¡œ ê²Œì‹œê¸€ ìŠ¹ì¸/ê±°ì ˆ
- ğŸ“¤ **ìë™ ì—…ë¡œë“œ**: ìœ íŠœë¸Œ ì‡¼ì¸  ìë™ ì—…ë¡œë“œ (Phase 3)

### ğŸ—ï¸ ì‹œìŠ¤í…œ í”Œë¡œìš°

```
ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ â†’ MariaDB ì €ì¥ â†’ Streamlit ê²€ìˆ˜ â†’ AI ì›Œì»¤(LLM/TTS) â†’ FFmpeg ë Œë”ë§ â†’ YouTube ì—…ë¡œë“œ
```

### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

| ë¶„ë¥˜ | ê¸°ìˆ  |
|------|------|
| **ì–¸ì–´** | Python 3.12 |
| **AI** | EEVE-Korean-10.8B (4-bit), Kokoro-82M TTS |
| **DB** | MariaDB 11.x + SQLAlchemy ORM |
| **ì˜ìƒ** | FFmpeg (h264_nvenc ì½”ë±) |
| **ì›¹** | Streamlit Dashboard |
| **ì¸í”„ë¼** | Docker Compose (GPU ì§€ì›) |

---

## ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ í•˜ë“œì›¨ì–´
- **GPU**: NVIDIA RTX 3080 Ti (12GB VRAM) ì´ìƒ
- **RAM**: 16GB ì´ìƒ
- **ì €ì¥ê³µê°„**: SSD 50GB ì´ìƒ

### í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´
- **OS**: Windows 10/11
- **WSL2**: Ubuntu 22.04
- **ì»¨í…Œì´ë„ˆ**: Podman 4.x + podman-compose (`sudo apt install podman podman-compose`)
- **GPU ë“œë¼ì´ë²„**: NVIDIA ë“œë¼ì´ë²„ 525.xx ì´ìƒ
- **ê¸°íƒ€**: Git, NVIDIA Container Toolkit (CDI ìŠ¤í™ ìƒì„± í•„ìˆ˜)

> **ì£¼ì˜:** Docker Desktop ëŒ€ì‹  **Podman**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. docker-compose v1ì€ GPU CDI í‘œê¸°ë²•(`nvidia.com/gpu=all`)ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ podman-composeë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸš€ ì„¤ì¹˜ ê°€ì´ë“œ

### 1ï¸âƒ£ WSL2 ë° Ubuntu ì„¤ì¹˜

```powershell
# PowerShell ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰

# WSL í™œì„±í™”
wsl --install

# ì¬ë¶€íŒ… í›„ Ubuntu 22.04 ì„¤ì¹˜
wsl --install -d Ubuntu-22.04

# ì„¤ì¹˜ í™•ì¸
wsl -l -v
# ì¶œë ¥: Ubuntu-22.04  Running  2
```

### 2ï¸âƒ£ Podman + podman-compose ì„¤ì¹˜

```bash
# WSL Ubuntu í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
sudo apt-get update
sudo apt-get install -y podman podman-compose

# ì„¤ì¹˜ í™•ì¸
podman --version   # Podman 4.x ì´ìƒ
podman-compose --version
```

### 3ï¸âƒ£ NVIDIA GPU ë“œë¼ì´ë²„ ì„¤ì¹˜

```bash
# WSLì—ì„œ í™•ì¸ (CUDA Toolkit ì„¤ì¹˜ ë¶ˆí•„ìš”)
nvidia-smi

# ì¶œë ¥ ì˜ˆì‹œ:
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 525.xx.xx    Driver Version: 525.xx.xx    CUDA Version: 12.x    |
# +-----------------------------------------------------------------------------+
```

### 4ï¸âƒ£ NVIDIA Container Toolkit ì„¤ì¹˜

```bash
# 1. íŒ¨í‚¤ì§€ ì €ì¥ì†Œ ë° GPG í‚¤ ì„¤ì •
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
  sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# 2. íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# 3. (Podman ì‚¬ìš©ì í•„ìˆ˜) CDI ìŠ¤í™ ìƒì„±
# ì´ ë‹¨ê³„ê°€ ì—†ìœ¼ë©´ "CUDA not available" ë˜ëŠ” "unresolvable CDI devices" ì—ëŸ¬ ë°œìƒ
sudo mkdir -p /etc/cdi
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

# 4. GPU ì ‘ê·¼ í…ŒìŠ¤íŠ¸
sudo podman run --rm --device nvidia.com/gpu=all \
  docker.io/nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### 5ï¸âƒ£ Ollama ì„¤ì¹˜ ë° ì„¤ì • (LLM ì„œë²„)

```bash
# 1. ì••ì¶• í•´ì œ ë„êµ¬ ì„¤ì¹˜
sudo apt-get install -y zstd

# 2. Ollama ì„¤ì¹˜ (systemd ì„œë¹„ìŠ¤ ìë™ ë“±ë¡)
curl -fsSL https://ollama.com/install.sh | sh

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (Qwen 2.5 14B - í•œêµ­ì–´ ì„±ëŠ¥ ìµœì )
ollama pull qwen2.5:14b

# 4. ì»¨í…Œì´ë„ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì™¸ë¶€ ì ‘ì† í—ˆìš©
# ~/.bashrcê°€ ì•„ë‹Œ systemd ì„œë¹„ìŠ¤ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ì¬ë¶€íŒ… í›„ì—ë„ ìœ ì§€)
sudo systemctl edit ollama --force <<'EOF'
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
EOF

sudo systemctl restart ollama

# 5. ë™ì‘ í™•ì¸
curl http://127.0.0.1:11434/api/tags
```

### 6ï¸âƒ£ í”„ë¡œì íŠ¸ í´ë¡  ë° ì„¤ì •

```bash
# WSL Ubuntu í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
cd ~
git clone https://github.com/justant/WaggleBot.git
cd WaggleBot

# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ í¸ì§‘ (nano ë˜ëŠ” ë‹¤ë¥¸ ì—ë””í„° ì‚¬ìš©)
nano .env
```

**.env íŒŒì¼ ì„¤ì •:**
```env
# Database
DB_ROOT_PASSWORD=your_secure_password_here
DB_USER=wagglebot
DB_PASSWORD=another_secure_password

# Hugging Face (LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
HF_TOKEN=hf_your_token_here  # https://huggingface.co/settings/tokens

# YouTube API (Phase 3ì—ì„œ ì‚¬ìš©)
YOUTUBE_API_KEY=your_youtube_api_key
YOUTUBE_CLIENT_ID=your_client_id
YOUTUBE_CLIENT_SECRET=your_client_secret
```

**Hugging Face í† í° ë°œê¸‰ ë°©ë²•:**
1. https://huggingface.co/ íšŒì›ê°€ì…/ë¡œê·¸ì¸
2. Settings â†’ Access Tokens â†’ New token ìƒì„±
3. Tokenì„ `.env` íŒŒì¼ì˜ `HF_TOKEN`ì— ì…ë ¥

### 7ï¸âƒ£ .gitignore ì„¤ì •

```bash
# ë¯¼ê°í•œ íŒŒì¼ì„ Git ì¶”ì ì—ì„œ ì œì™¸
cat >> .gitignore << 'EOF'

# í™˜ê²½ íŒŒì¼
.env

# Python ìºì‹œ
__pycache__/
*.pyc
*.pyo

# Docker ë³¼ë¥¨ ë°ì´í„°
media/
models_cache/

# Claude Code ê°œì¸ ì„¤ì •
.claude/settings.local.json
EOF
```

### 8ï¸âƒ£ ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
# ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„¤ì • (ìµœì´ˆ 1íšŒ - short name í•´ì„ í•„ìš”)
echo 'unqualified-search-registries = ["docker.io"]' | sudo tee -a /etc/containers/registries.conf

# ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹œì‘
sudo podman-compose up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo podman ps

# ì¶œë ¥ ì˜ˆì‹œ:
#        Name                      State           Ports
# --------------------------------------------------------------
# wagglebot_db          Up      3306/tcp
# wagglebot_crawler     Up
# wagglebot_ai_worker   Up (healthy)
# wagglebot_dashboard   Up      0.0.0.0:8501->8501/tcp
```

### 9ï¸âƒ£ ì„¤ì¹˜ í™•ì¸

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
sudo podman exec wagglebot_db_1 mariadb-admin ping -h localhost

# GPU ì£¼ì… í™•ì¸
sudo podman exec wagglebot_ai_worker_1 python3 -c \
  "import torch; print('CUDA:', torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')"

# AI ì›Œì»¤ ë¡œê·¸ í™•ì¸
sudo podman logs wagglebot_ai_worker_1 2>&1 | tail -20

# ëŒ€ì‹œë³´ë“œ ì ‘ì†
# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì—´ê¸°
```

---

## ğŸ® ì‚¬ìš©ë²•

### 1. í¬ë¡¤ëŸ¬ ì‹¤í–‰

```bash
# 1íšŒ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)
docker exec wagglebot_crawler python main.py --once

# ìŠ¤ì¼€ì¤„ ì‹¤í–‰ (1ì‹œê°„ë§ˆë‹¤ ìë™) - ì´ë¯¸ ì‹¤í–‰ ì¤‘
# docker-compose.ymlì— ì •ì˜ë¨
```

### 2. ëŒ€ì‹œë³´ë“œ ì‚¬ìš©

http://localhost:8501 ì ‘ì†

#### ğŸ“¥ ìˆ˜ì‹ í•¨ íƒ­
- **í•„í„°ë§**: ì‚¬ì´íŠ¸ë³„, ì´ë¯¸ì§€ ìœ ë¬´, ì •ë ¬ ê¸°ì¤€
- **ê²Œì‹œê¸€ í™•ì¸**: ì œëª©, ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°, ë² ìŠ¤íŠ¸ ëŒ“ê¸€
- **[ìŠ¹ì¸]** ë²„íŠ¼: AI ì›Œì»¤ê°€ ìë™ìœ¼ë¡œ ì˜ìƒ ìƒì„± ì‹œì‘
- **[ê±°ì ˆ]** ë²„íŠ¼: í•´ë‹¹ ê²Œì‹œê¸€ ì œì™¸

#### âš™ï¸ ì§„í–‰ ìƒíƒœ íƒ­
- **ëŒ€ê¸°ì¤‘**: APPROVED ìƒíƒœ (AI ì›Œì»¤ ì²˜ë¦¬ ëŒ€ê¸°)
- **ì²˜ë¦¬ì¤‘**: PROCESSING ìƒíƒœ (LLM ìš”ì•½/TTS ìƒì„± ì¤‘)
- **ë Œë”ë§ ì™„ë£Œ**: RENDERED ìƒíƒœ (ì˜ìƒ ìƒì„± ì™„ë£Œ)
- **ì—…ë¡œë“œ ì™„ë£Œ**: UPLOADED ìƒíƒœ (YouTube ì—…ë¡œë“œ ì™„ë£Œ)

#### ğŸ¬ ê°¤ëŸ¬ë¦¬ íƒ­
- ì™„ì„±ëœ ì˜ìƒ ì¬ìƒ
- ë‹¤ìš´ë¡œë“œ ë° ê³µìœ 

### 3. ì˜ìƒ ìƒì„± ê³¼ì •

```
ìŠ¹ì¸ â†’ LLM ìš”ì•½(30ì´ˆ) â†’ TTS ìƒì„±(20ì´ˆ) â†’ ì˜ìƒ ë Œë”ë§(1-2ë¶„) â†’ ì™„ë£Œ
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: ê²Œì‹œê¸€ 1ê°œë‹¹ ì•½ 2-5ë¶„

### 4. ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
docker-compose logs -f ai_worker

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker-compose logs -f crawler
docker-compose logs -f dashboard
docker-compose logs -f db

# ì—ëŸ¬ë§Œ í•„í„°ë§
docker-compose logs ai_worker | grep ERROR
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: GPU ì¥ì¹˜ ì—ëŸ¬ (`no such file or directory`)

**ì¦ìƒ:**
```
error gathering device information while adding custom device "nvidia.com/gpu=all": no such file or directory
```

**ì›ì¸:** `docker-compose v1`ì´ CDI í‘œê¸°ë²•(`nvidia.com/gpu=all`)ì„ íŒŒì¼ ê²½ë¡œë¡œ ì˜¤í•´í•¨

**í•´ê²°:**
```bash
# 1. podman-compose ì‚¬ìš© (docker-compose v1 ëŒ€ì²´)
sudo apt install podman-compose

# 2. CDI ìŠ¤í™ ìƒì„± (ìµœì´ˆ 1íšŒ)
sudo mkdir -p /etc/cdi
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

# 3. registries.conf ì„¤ì • (ìµœì´ˆ 1íšŒ)
echo 'unqualified-search-registries = ["docker.io"]' | sudo tee -a /etc/containers/registries.conf

# 4. podman-composeë¡œ ì‹¤í–‰
sudo podman-compose up -d

# 5. GPU ì£¼ì… í™•ì¸
sudo podman exec wagglebot_ai_worker_1 python3 -c \
  "import torch; print('CUDA:', torch.cuda.is_available())"
```

### ë¬¸ì œ 1-1: Ollama ì—°ê²° ì‹¤íŒ¨ (`Connection refused`)

**ì¦ìƒ:**
```
ConnectionError: HTTPConnectionPool(host='host.containers.internal', port=11434):
  Failed to establish a new connection: [Errno 111] Connection refused
```

**ì›ì¸:** ë¸Œë¦¬ì§€ ë„¤íŠ¸ì›Œí¬ì—ì„œ `host.containers.internal` DNSê°€ WSL2ì—ì„œ ë¶ˆì•ˆì •í•¨
`ai_worker`ëŠ” `network_mode: host`ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ `127.0.0.1:11434`ë¡œ Ollamaì— ì§ì ‘ ì—°ê²°ë¨

**í•´ê²°:** `docker-compose.yml` í™•ì¸
```yaml
ai_worker:
  network_mode: host   # ì´ ì¤„ì´ ìˆì–´ì•¼ í•¨
  environment:
    OLLAMA_HOST: "http://127.0.0.1:11434"   # host.containers.internal ì•„ë‹˜
    DATABASE_URL: "...@127.0.0.1:3306/..."  # db ì•„ë‹˜
```

### ë¬¸ì œ 2: MariaDB ì ‘ì† ì‹¤íŒ¨

**ì¦ìƒ:**
```
Can't connect to MySQL server on 'db'
```

**í•´ê²°:**
```bash
# 1. DB ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps db

# 2. í—¬ìŠ¤ì²´í¬ í™•ì¸
docker inspect wagglebot_db | grep -A 10 Health

# 3. .env íŒŒì¼ ë¹„ë°€ë²ˆí˜¸ í™•ì¸
cat .env | grep DB_PASSWORD

# 4. DB ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart db

# 5. ì´ˆê¸°í™” (ì£¼ì˜: ëª¨ë“  ë°ì´í„° ì‚­ì œ)
docker-compose down -v
docker-compose up -d
```

### ë¬¸ì œ 3: OOM (Out of Memory) ì—ëŸ¬

**ì¦ìƒ:**
```
CUDA out of memory. Tried to allocate 2.00 GiB
```

**í•´ê²°:**
```bash
# 1. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# 2. ë‹¤ë¥¸ GPU ì‚¬ìš© í”„ë¡œê·¸ë¨ ì¢…ë£Œ (Chrome, ê²Œì„ ë“±)

# 3. ai_worker ì¬ì‹œì‘
docker-compose restart ai_worker

# 4. VRAM ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸° (config/settings.py ìˆ˜ì •)
# LLM_MAX_LENGTH = 512  # ê¸°ë³¸ê°’: 1024
# TTS_BATCH_SIZE = 1     # ê¸°ë³¸ê°’: 4
```

### ë¬¸ì œ 4: FFmpeg ì¸ì½”ë”© ì‹¤íŒ¨

**ì¦ìƒ:**
```
Unknown encoder 'h264_nvenc'
```

**í•´ê²°:**
```bash
# 1. FFmpeg NVENC ì§€ì› í™•ì¸
docker exec wagglebot_ai_worker ffmpeg -encoders | grep nvenc

# 2. GPU ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸ (Windows)

# 3. h264_nvenc â†’ libx264ë¡œ ì„ì‹œ ë³€ê²½ (ëŠë¦¼)
# ai_worker/renderer.py ìˆ˜ì •:
# codec='libx264'  # h264_nvenc ëŒ€ì‹ 
```

### ë¬¸ì œ 5: í¬ë¡¤ëŸ¬ê°€ ê²Œì‹œê¸€ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í•¨

**ì¦ìƒ:**
- ëŒ€ì‹œë³´ë“œ ìˆ˜ì‹ í•¨ì´ ë¹„ì–´ìˆìŒ

**í•´ê²°:**
```bash
# 1. í¬ë¡¤ëŸ¬ ë¡œê·¸ í™•ì¸
docker-compose logs crawler | tail -50

# 2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
docker exec wagglebot_crawler ping -c 3 pann.nate.com

# 3. ìˆ˜ë™ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
docker exec wagglebot_crawler python main.py --once

# 4. ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ì—¬ë¶€ í™•ì¸ (crawlers/nate.py ìˆ˜ì • í•„ìš”)
```

### ë¬¸ì œ 6: ëŒ€ì‹œë³´ë“œê°€ ì—´ë¦¬ì§€ ì•ŠìŒ

**ì¦ìƒ:**
- http://localhost:8501 ì ‘ì† ë¶ˆê°€

**í•´ê²°:**
```bash
# 1. ëŒ€ì‹œë³´ë“œ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps dashboard

# 2. í¬íŠ¸ ì¶©ëŒ í™•ì¸
netstat -ano | findstr :8501

# 3. ëŒ€ì‹œë³´ë“œ ë¡œê·¸ í™•ì¸
docker-compose logs dashboard

# 4. ëŒ€ì‹œë³´ë“œ ì¬ì‹œì‘
docker-compose restart dashboard
```

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
WaggleBot/
â”œâ”€â”€ ğŸ“„ CLAUDE.md                   # Claude Code ì‚¬ìš© ì‹œ ê°œë°œ ê·œì¹™
â”œâ”€â”€ ğŸ“„ README.md                   # ì´ íŒŒì¼
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Docker êµ¬ì„±
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python ì˜ì¡´ì„±
â”œâ”€â”€ ğŸ“ arch/                       # ì•„í‚¤í…ì²˜ ë¬¸ì„œ
â”‚   â””â”€â”€ dev_spec.md                # ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ì„œ
â”œâ”€â”€ ğŸ“ crawlers/                   # í¬ë¡¤ëŸ¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ base.py                    # BaseCrawler ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â””â”€â”€ nate.py                    # ë„¤ì´íŠ¸íŒ í¬ë¡¤ëŸ¬
â”œâ”€â”€ ğŸ“ db/                         # ë°ì´í„°ë² ì´ìŠ¤
â”‚   â”œâ”€â”€ models.py                  # SQLAlchemy ëª¨ë¸
â”‚   â””â”€â”€ session.py                 # DB ì„¸ì…˜ ê´€ë¦¬
â”œâ”€â”€ ğŸ“ ai_worker/                  # AI ì›Œì»¤
â”‚   â”œâ”€â”€ main.py                    # DB í´ë§ ë©”ì¸ ë£¨í”„
â”‚   â”œâ”€â”€ llm.py                     # LLM ìš”ì•½ê¸°
â”‚   â”œâ”€â”€ tts.py                     # TTS ìƒì„±ê¸°
â”‚   â””â”€â”€ renderer.py                # FFmpeg ì˜ìƒ ë Œë”ëŸ¬
â”œâ”€â”€ ğŸ“ assets/                     # ì •ì  ë¦¬ì†ŒìŠ¤
â”‚   â”œâ”€â”€ backgrounds/               # 9:16 ë°°ê²½ ì˜ìƒ
â”‚   â””â”€â”€ fonts/                     # í•œê¸€ í°íŠ¸
â”œâ”€â”€ ğŸ“ config/                     # ì„¤ì •
â”‚   â””â”€â”€ settings.py                # ì¤‘ì•™í™”ëœ ì„¤ì •
â”œâ”€â”€ ğŸ“ monitoring/                 # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ alerting.py                # ì•Œë¦¼ ê´€ë¦¬ì
â”‚   â””â”€â”€ daemon.py                  # í—¬ìŠ¤ì²´í¬ ë°ëª¬
â”œâ”€â”€ ğŸ“„ main.py                     # í¬ë¡¤ëŸ¬ ì§„ì…ì 
â”œâ”€â”€ ğŸ“„ scheduler.py                # Cron ìŠ¤ì¼€ì¤„ëŸ¬
â””â”€â”€ ğŸ“„ dashboard.py                # Streamlit ëŒ€ì‹œë³´ë“œ
```

---

## ğŸ“Š ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§

### ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

WaggleBotì€ ì‹œìŠ¤í…œ í—¬ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , ë¬¸ì œ ë°œìƒ ì‹œ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.

#### ëª¨ë‹ˆí„°ë§ í•­ëª©

- **CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
- **ë””ìŠ¤í¬ ê³µê°„**: ì˜ìƒ ì €ì¥ ê³µê°„ í™•ì¸
- **GPU ì˜¨ë„**: ê³¼ì—´ ë°©ì§€ (ê²½ê³ : 75Â°C, ìœ„í—˜: 80Â°C)
- **DB ì—°ê²°**: ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì²´í¬

#### ì•Œë¦¼ ì„¤ì •

**.env íŒŒì¼ ì„¤ì •:**

```bash
# ëª¨ë‹ˆí„°ë§ í™œì„±í™”
MONITORING_ENABLED=true
HEALTH_CHECK_INTERVAL=300  # 5ë¶„ë§ˆë‹¤ ì²´í¬

# ì„ê³„ê°’ ì„¤ì •
GPU_TEMP_WARNING=75
GPU_TEMP_CRITICAL=80
DISK_USAGE_WARNING=80
DISK_USAGE_CRITICAL=90

# ì´ë©”ì¼ ì•Œë¦¼ (Gmail ì˜ˆì‹œ)
EMAIL_ALERTS_ENABLED=true
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASSWORD=your_app_password  # Gmail ì•± ë¹„ë°€ë²ˆí˜¸
ALERT_EMAIL_TO=admin@example.com,dev@example.com

# ìŠ¬ë™ ì•Œë¦¼
SLACK_ALERTS_ENABLED=true
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

**Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ìƒì„±:**
1. Google ê³„ì • â†’ ë³´ì•ˆ â†’ 2ë‹¨ê³„ ì¸ì¦ í™œì„±í™”
2. ì•± ë¹„ë°€ë²ˆí˜¸ ìƒì„± â†’ "ë©”ì¼" ì„ íƒ
3. ìƒì„±ëœ 16ì ë¹„ë°€ë²ˆí˜¸ë¥¼ `SMTP_PASSWORD`ì— ì…ë ¥

#### ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# Docker Composeë¡œ ì‹œì‘
docker-compose up -d monitoring

# ë¡œê·¸ í™•ì¸
docker-compose logs -f monitoring

# ìˆ˜ë™ í…ŒìŠ¤íŠ¸
python test_monitoring.py
```

#### ëª¨ë‹ˆí„°ë§ ë¡œê·¸ ì˜ˆì‹œ

```
2025-02-15 12:00:00 - monitoring.alerting - INFO - Starting health check...
2025-02-15 12:00:01 - monitoring.alerting - INFO - CPU: 45.2% | MEM: 62.1% | DISK: 55.3% | GPU: 68Â°C | DB: OK
2025-02-15 12:00:01 - monitoring.alerting - INFO - Health check OK
```

**ì•Œë¦¼ì´ ì „ì†¡ë˜ëŠ” ê²½ìš°:**
- âš ï¸ **WARNING**: GPU 75Â°C ì´ìƒ, ë””ìŠ¤í¬ 80% ì´ìƒ (ë¡œê·¸ë§Œ)
- ğŸš¨ **CRITICAL**: GPU 80Â°C ì´ìƒ, ë””ìŠ¤í¬ 90% ì´ìƒ, DB ì—°ê²° ì‹¤íŒ¨ (ì´ë©”ì¼/ìŠ¬ë™ ì „ì†¡)

---

## ğŸ›¡ï¸ ì—ëŸ¬ í•¸ë“¤ë§ ë° ë³µêµ¬

### ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ

WaggleBotì€ AI ì›Œì»¤ ì²˜ë¦¬ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—ëŸ¬ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ë³µêµ¬í•©ë‹ˆë‹¤.

#### ì—ëŸ¬ íƒ€ì… ë¶„ë¥˜

- **LLM_ERROR**: LLM ìš”ì•½ ì‹¤íŒ¨ (ì¬ì‹œë„ ë¶ˆê°€ - ì¦‰ì‹œ FAILED ì²˜ë¦¬)
- **TTS_ERROR**: TTS ìŒì„± ìƒì„± ì‹¤íŒ¨ (ì¬ì‹œë„ ê°€ëŠ¥)
- **RENDER_ERROR**: ì˜ìƒ ë Œë”ë§ ì‹¤íŒ¨ (ì¬ì‹œë„ ê°€ëŠ¥)
- **NETWORK_ERROR**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ (ì¬ì‹œë„ ê°€ëŠ¥)
- **RESOURCE_ERROR**: VRAM/ë””ìŠ¤í¬ ë¶€ì¡± (ì¬ì‹œë„ ê°€ëŠ¥)
- **UNKNOWN_ERROR**: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ (ì¬ì‹œë„ ê°€ëŠ¥)

#### ì¬ì‹œë„ ì •ì±… (Exponential Backoff)

```python
# ê¸°ë³¸ ì„¤ì • (.env)
MAX_RETRY_COUNT=3          # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
BACKOFF_FACTOR=2.0         # 2ë°°ì”© ì¦ê°€
INITIAL_DELAY=5.0          # ì²« ì¬ì‹œë„ 5ì´ˆ í›„

# ì¬ì‹œë„ íƒ€ì„ë¼ì¸ ì˜ˆì‹œ
# 1ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ 5ì´ˆ ëŒ€ê¸°
# 2ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ 10ì´ˆ ëŒ€ê¸°
# 3ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ 20ì´ˆ ëŒ€ê¸°
# â†’ FAILED ìƒíƒœë¡œ ì „í™˜
```

#### ì²˜ë¦¬ íë¦„

```
APPROVED â†’ PROCESSING
    â†“
[Step 1] LLM ìš”ì•½ ìƒì„±
    â”œâ”€ ì„±ê³µ â†’ Step 2
    â””â”€ ì‹¤íŒ¨ â†’ ì¦‰ì‹œ FAILED (ì¬ì‹œë„ ë¶ˆê°€)
    â†“
[Step 2] TTS ìŒì„± ìƒì„±
    â”œâ”€ ì„±ê³µ â†’ Step 3
    â””â”€ ì‹¤íŒ¨ â†’ Backoff í›„ ì¬ì‹œë„
    â†“
[Step 3] ì˜ìƒ ë Œë”ë§
    â”œâ”€ ì„±ê³µ â†’ RENDERED
    â””â”€ ì‹¤íŒ¨ â†’ Backoff í›„ ì¬ì‹œë„
    â†“
ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ â†’ FAILED
```

#### ì—ëŸ¬ ë¡œê·¸ í™•ì¸

**failures.log íŒŒì¼:**
```bash
# ì—ëŸ¬ ë¡œê·¸ ìœ„ì¹˜
media/logs/failures.log

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
tail -f media/logs/failures.log

# ì˜ˆì‹œ
2025-02-15T12:00:00 | post_id=123 | failure_type=tts_error | attempt=1 | error=TTS synthesis failed
2025-02-15T12:00:10 | post_id=123 | failure_type=tts_error | attempt=2 | error=TTS synthesis failed
```

**ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸:**
- **ì§„í–‰í˜„í™© íƒ­**: FAILED ìƒíƒœ ê²Œì‹œê¸€ í™•ì¸
- **ì¬ì‹œë„ ë²„íŠ¼**: ì‹¤íŒ¨í•œ ê²Œì‹œê¸€ì„ APPROVEDë¡œ ë˜ëŒë ¤ ì¬ì²˜ë¦¬

#### í…ŒìŠ¤íŠ¸

```bash
# ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_error_handling.py

# ì˜ˆìƒ ì¶œë ¥
âœ“ LLM ì—ëŸ¬ ë¶„ë¥˜ ì„±ê³µ
âœ“ TTS ì—ëŸ¬ ë¶„ë¥˜ ì„±ê³µ
âœ“ Backoff ê³„ì‚° ì„±ê³µ
âœ“ LLM ì—ëŸ¬ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨ í™•ì¸
âœ“ TTS ì—ëŸ¬ ì¬ì‹œë„ ë¡œì§ í™•ì¸
```

#### ìˆ˜ë™ ë³µêµ¬

**ì‹¤íŒ¨í•œ ê²Œì‹œê¸€ ì¬ì²˜ë¦¬:**
```python
# Python ìŠ¤í¬ë¦½íŠ¸
from db.session import SessionLocal
from db.models import Post, PostStatus

with SessionLocal() as session:
    # ì‹¤íŒ¨í•œ ê²Œì‹œê¸€ ì¡°íšŒ
    failed_post = session.query(Post).filter_by(status=PostStatus.FAILED).first()

    # APPROVEDë¡œ ë³€ê²½í•˜ì—¬ ì¬ì‹œë„ íì— ì¶”ê°€
    failed_post.status = PostStatus.APPROVED
    failed_post.retry_count = 0  # ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    session.commit()
```

**ë˜ëŠ” ëŒ€ì‹œë³´ë“œì—ì„œ:**
1. ì§„í–‰í˜„í™© íƒ­ ì´ë™
2. FAILED ì„¹ì…˜ì—ì„œ ê²Œì‹œê¸€ í™•ì¸
3. "ğŸ”„ ì¬ì‹œë„" ë²„íŠ¼ í´ë¦­

---

## ğŸ® GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

### ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

RTX 3080 Ti (12GB VRAM)ì˜ ì œí•œëœ ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

#### ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ

**ë¬¸ì œì :**
- LLM (4.5GB) + TTS (2.5GB) ë™ì‹œ ë¡œë“œ ë¶ˆê°€ëŠ¥
- OOM (Out of Memory) ë°œìƒ ì‹œ ì»¨í…Œì´ë„ˆ í¬ë˜ì‹œ

**í•´ê²°ì±…:**
- âœ… ìˆœì°¨ ì²˜ë¦¬: LLM â†’ TTS â†’ ë Œë”ë§
- âœ… ìë™ ì–¸ë¡œë“œ: ë‹¤ìŒ ëª¨ë¸ ë¡œë“œ ì „ ì´ì „ ëª¨ë¸ ì •ë¦¬
- âœ… ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €: ìë™ ë©”ëª¨ë¦¬ í•´ì œ
- âœ… ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: ì‹¤ì‹œê°„ VRAM ì¶”ì 

#### ì‚¬ìš© ë°©ë²•

**ì½”ë“œì—ì„œ ì‚¬ìš© (ìë™):**
```python
from ai_worker.gpu_manager import get_gpu_manager, ModelType

gpu_manager = get_gpu_manager()

# ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬
with gpu_manager.managed_inference(ModelType.LLM, "summarizer"):
    summary = llm_model.generate(text)
    # ë¸”ë¡ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ í•´ì œ

with gpu_manager.managed_inference(ModelType.TTS, "tts_engine"):
    audio = tts_model.synthesize(summary)
    # LLM ë©”ëª¨ë¦¬ ìë™ ì–¸ë¡œë“œë¨
```

**ë©”ëª¨ë¦¬ í™•ì¸:**
```python
# ì‚¬ìš© ê°€ëŠ¥í•œ VRAM ì¡°íšŒ
available_gb = gpu_manager.get_available_vram()
print(f"Available: {available_gb:.2f} GB")

# ëª¨ë¸ ë¡œë“œ ê°€ëŠ¥ ì—¬ë¶€
can_load = gpu_manager.can_load_model(required_vram_gb=4.5)

# ë©”ëª¨ë¦¬ í†µê³„
stats = gpu_manager.get_memory_stats()
print(f"Usage: {stats.usage_percent:.1f}%")

# ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê·¸
gpu_manager.log_memory_status()
```

#### ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

**ë¡œê·¸ ì¶œë ¥:**
```bash
# AI ì›Œì»¤ ë¡œê·¸ í™•ì¸
docker-compose logs -f ai_worker | grep GPU

# ì˜ˆì‹œ ì¶œë ¥
[GPU] Memory: 3.45 / 11.91 GB (29.0% used, 8.46 GB free)
[GPU] Loaded models: 1
  - summarizer (llm): ~4.5 GB
```

**ìˆ˜ë™ ë©”ëª¨ë¦¬ ì •ë¦¬:**
```python
# ì¼ë°˜ ì •ë¦¬
gpu_manager.cleanup_memory()

# ê¸´ê¸‰ ì •ë¦¬ (ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ)
gpu_manager.emergency_cleanup()
```

#### í…ŒìŠ¤íŠ¸

```bash
# GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
python test_gpu_manager.py

# ì˜ˆìƒ ì¶œë ¥
âœ“ CUDA ì‚¬ìš© ê°€ëŠ¥
  ë””ë°”ì´ìŠ¤ ìˆ˜: 1
  ë””ë°”ì´ìŠ¤ ì´ë¦„: NVIDIA GeForce RTX 3080 Ti
âœ“ ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ ì„±ê³µ
âœ“ ê´€ë¦¬ëœ ì¶”ë¡  ì„±ê³µ
âœ“ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!
```

#### ë©”ëª¨ë¦¬ ìµœì í™” íŒ

1. **4-bit ì–‘ìí™” ì‚¬ìš©**
   ```python
   # LLM ë¡œë“œ ì‹œ ë°˜ë“œì‹œ 4-bit ì–‘ìí™”
   model = AutoModelForCausalLM.from_pretrained(
       model_name,
       load_in_4bit=True,  # í•„ìˆ˜!
       device_map="auto"
   )
   ```

2. **ëª¨ë¸ ìˆœì°¨ ì²˜ë¦¬**
   - LLM â†’ ë©”ëª¨ë¦¬ í•´ì œ â†’ TTS â†’ ë©”ëª¨ë¦¬ í•´ì œ â†’ ë Œë”ë§

3. **FFmpeg NVENC ì‚¬ìš©**
   ```bash
   # GPU ê°€ì† (ê¶Œì¥)
   codec='h264_nvenc'

   # CPU ì¸ì½”ë”© (ê¸ˆì§€ - VRAM ì°¨ë‹¨)
   # codec='libx264'  âŒ
   ```

4. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ëŒ€ì‘**
   - ìë™: GPUMemoryManagerê°€ ìë™ ì²˜ë¦¬
   - ìˆ˜ë™: `gpu_manager.emergency_cleanup()`

#### í•˜ë“œì›¨ì–´ë³„ ì„¤ì •

| GPU ëª¨ë¸ | VRAM | LLM | TTS | ë™ì‹œ ë¡œë“œ | ê¶Œì¥ ì„¤ì • |
|----------|------|-----|-----|-----------|-----------|
| **RTX 3080 Ti** | 12GB | 4-bit | ê°€ëŠ¥ | âŒ ë¶ˆê°€ | ìˆœì°¨ ì²˜ë¦¬ (í˜„ì¬) |
| **RTX 3090** | 24GB | 4-bit | ê°€ëŠ¥ | âœ… ê°€ëŠ¥ | ë™ì‹œ ë¡œë“œ ê°€ëŠ¥ |
| **RTX 4090** | 24GB | 8-bit | ê°€ëŠ¥ | âœ… ê°€ëŠ¥ | ê³ í’ˆì§ˆ ëª¨ë¸ |

í˜„ì¬ ì„¤ì •ì€ **RTX 3080 Ti 12GB**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ‘¨â€ğŸ’» ê°œë°œ ê°€ì´ë“œ

### ê¸°ë³¸ ê°œë°œ í™˜ê²½

```bash
# Python ì˜ì¡´ì„± ì„¤ì¹˜ (ë¡œì»¬ ê°œë°œ ì‹œ)
pip install -r requirements.txt

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
python -c "from db.session import init_db; init_db()"

# í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
python main.py --once

# ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ (ë¡œì»¬)
streamlit run dashboard.py
```

### í¬ë¡¤ëŸ¬ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

WaggleBotì€ **í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜**ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ë¡¤ëŸ¬ë¥¼ ë™ì ìœ¼ë¡œ ë“±ë¡í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

#### ì‚¬ìš© ê°€ëŠ¥í•œ í¬ë¡¤ëŸ¬ í™•ì¸

```bash
# ë“±ë¡ëœ í¬ë¡¤ëŸ¬ ëª©ë¡ ë³´ê¸°
python main.py --list

# ì¶œë ¥ ì˜ˆì‹œ
[nate_pann] (ENABLED)
  Class: NatePannCrawler
  Module: crawlers.nate_pann
  Description: ë„¤ì´íŠ¸íŒ ì¸ê¸°ê¸€ í¬ë¡¤ëŸ¬
```

#### í¬ë¡¤ëŸ¬ í™œì„±í™”/ë¹„í™œì„±í™”

**.env íŒŒì¼ì—ì„œ ì„¤ì •:**
```bash
# ë‹¨ì¼ í¬ë¡¤ëŸ¬
ENABLED_CRAWLERS=nate_pann

# ë³µìˆ˜ í¬ë¡¤ëŸ¬ (ì½¤ë§ˆë¡œ êµ¬ë¶„)
ENABLED_CRAWLERS=nate_pann,nate_tok,reddit
```

#### ìƒˆ í¬ë¡¤ëŸ¬ ì¶”ê°€í•˜ê¸°

**1. í¬ë¡¤ëŸ¬ íŒŒì¼ ìƒì„± (`crawlers/reddit.py`)**

**2. .envì— ì¶”ê°€**
```bash
ENABLED_CRAWLERS=nate_pann,reddit
```

**3. ìë™ ë°œê²¬ í™•ì¸**
```bash
# í¬ë¡¤ëŸ¬ê°€ ìë™ìœ¼ë¡œ ë°œê²¬ë˜ê³  ë“±ë¡ë¨
python main.py --list

# ì‹¤í–‰
python main.py --once
```

#### í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ íŠ¹ì§•

âœ… **ìë™ ë°œê²¬**: `crawlers/` ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  í¬ë¡¤ëŸ¬ ìë™ ë“±ë¡
âœ… **ë°ì½”ë ˆì´í„° ê¸°ë°˜**: `@CrawlerRegistry.register()` ì‚¬ìš©
âœ… **ë™ì  í™œì„±í™”**: `.env`ì—ì„œ í™œì„±í™”/ë¹„í™œì„±í™” ê°€ëŠ¥
âœ… **ë©”íƒ€ë°ì´í„°**: ì„¤ëª…, í™œì„±í™” ìƒíƒœ ë“± ê´€ë¦¬
âœ… **í™•ì¥ì„±**: 100ê°œ ì´ìƒ í¬ë¡¤ëŸ¬ ì§€ì› ê°€ëŠ¥

---

### YAML ê¸°ë°˜ í¬ë¡¤ëŸ¬ (ì½”ë“œ ì—†ì´ ì¶”ê°€)

**í”„ë¡œê·¸ë˜ë° ì—†ì´** YAML ì„¤ì •ë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ì‚¬ì´íŠ¸ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

#### ì„¤ì • íŒŒì¼ êµ¬ì¡°

**`config/sites.yaml`**

```yaml
sites:
  my_site:
    enabled: true
    description: "ë‚´ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬"

    # í¬ë¡¤ë§ ì„¤ì •
    interval_minutes: 60
    max_pages: 3

    # URL íŒ¨í„´
    listing_url: "https://example.com/popular"
    post_url_template: "https://example.com/post/{origin_id}"

    # CSS ì…€ë ‰í„°
    selectors:
      # ëª©ë¡ í˜ì´ì§€
      listing_items: "div.post-list li"
      listing_link: "a.post-link"
      listing_title: "h3.title"

      # ìƒì„¸ í˜ì´ì§€
      title: "h1.post-title"
      content: "div.post-content"
      images: "div.post-content img"

      # í†µê³„
      views: "span.view-count"
      likes: "span.like-count"

      # ëŒ“ê¸€
      comments_section: "div.comments"
      comment_item: "li.comment"
      comment_author: "span.author"
      comment_content: "p.content"
      comment_likes: "span.likes"

    # íŒŒì‹± ê·œì¹™
    parsing:
      origin_id_pattern: "/post/(\\d+)"
      stats_extract_digits: true
      image_attrs: ["src", "data-src"]

    # Rate Limiting
    rate_limit:
      requests_per_minute: 30
      delay_between_posts: 0.5
```

#### YAML í¬ë¡¤ëŸ¬ ì¶”ê°€ ë‹¨ê³„

**1. `config/sites.yaml`ì— ì‚¬ì´íŠ¸ ì¶”ê°€**

```yaml
sites:
  my_new_site:
    enabled: true
    description: "ìƒˆ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬"
    listing_url: "https://newsite.com/best"
    selectors:
      listing_items: "div.posts li"
      title: "h1"
      content: "article"
    parsing:
      origin_id_pattern: "/post/(\\w+)"
```

**2. `.env`ì— í™œì„±í™”**

```bash
ENABLED_CRAWLERS=nate_pann,my_new_site
```

**3. ì¦‰ì‹œ ì‹¤í–‰**

```bash
python main.py --once
```

ë! ë³„ë„ì˜ Python ì½”ë“œ ì‘ì„± ì—†ì´ í¬ë¡¤ëŸ¬ê°€ ë™ì‘í•©ë‹ˆë‹¤.

#### YAML vs ì½”ë“œ ê¸°ë°˜ í¬ë¡¤ëŸ¬

| ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‹œê¸° |
|------|------|------|-----------|
| **YAML ê¸°ë°˜** | ì½”ë“œ ë¶ˆí•„ìš”, ë¹ ë¥¸ ì¶”ê°€, ë¹„ê°œë°œì ê°€ëŠ¥ | ë³µì¡í•œ ë¡œì§ ë¶ˆê°€ | í‘œì¤€ì ì¸ HTML êµ¬ì¡° ì‚¬ì´íŠ¸ |
| **ì½”ë“œ ê¸°ë°˜** | ë³µì¡í•œ ë¡œì§ ê°€ëŠ¥, ì™„ì „í•œ ì œì–´ | ê°œë°œ ì‹œê°„ ì†Œìš” | íŠ¹ìˆ˜í•œ ì²˜ë¦¬ í•„ìš” ì‚¬ì´íŠ¸ |

**ê¶Œì¥:** ë¨¼ì € YAMLë¡œ ì‹œë„í•˜ê³ , ë³µì¡í•˜ë©´ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜

#### í…ŒìŠ¤íŠ¸

```bash
# YAML í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
python test_yaml_crawler.py

# ì˜ˆìƒ ì¶œë ¥
âœ“ 3ê°œ ì‚¬ì´íŠ¸ ì„¤ì • ë¡œë“œë¨
âœ“ nate_pann í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ
âœ“ ConfigurableCrawler í™•ì¸
âœ“ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!
```

ìì„¸í•œ ë‚´ìš©ì€ [arch/dev_spec.md](arch/dev_spec.md) ì°¸ì¡°.

### (ì„ íƒ) Claude Codeë¡œ ê°œë°œí•˜ê¸°

> **Claude Code**ëŠ” AI í˜ì–´ í”„ë¡œê·¸ë˜ë° ë„êµ¬ì…ë‹ˆë‹¤. ì‚¬ìš©ì€ ì„ íƒì‚¬í•­ì´ì§€ë§Œ, ìë™ ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±, ì½”ë“œ ë¦¬ë·°, ë²„ê·¸ ìˆ˜ì • ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

#### Claude Code ì„¤ì¹˜

1. [Claude Code ë‹¤ìš´ë¡œë“œ](https://code.claude.com)
2. ì„¤ì¹˜ í›„ Anthropic ê³„ì • ë¡œê·¸ì¸
3. Settings â†’ WSL â†’ Enable í™œì„±í™”

#### Claude Code ì„¤ì •

```bash
# .claude ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p .claude

# settings.local.json ìƒì„±
cat > .claude/settings.local.json << 'EOF'
{
  "permissions": {
    "allow": [
      "Bash(git add:*)",
      "Bash(git status:*)",
      "Bash(git diff:*)",
      "Bash(docker ps:*)",
      "Bash(pytest:*)"
    ],
    "ask": [
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(docker-compose up:*)"
    ],
    "deny": [
      "Bash(git push --force:main)",
      "Bash(DROP TABLE:*)"
    ]
  }
}
EOF

# .gitignoreì— ì¶”ê°€
echo ".claude/settings.local.json" >> .gitignore
```

#### Claude Code ì‚¬ìš©ë²•

```bash
# í”„ë¡œì íŠ¸ ì—´ê¸°
cd ~/WaggleBot
claude-code .

# Claudeì—ê²Œ ìš”ì²­ ì˜ˆì‹œ:
# "ë„¤ì´íŠ¸íŒ í¬ë¡¤ëŸ¬ì— ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€í•´ì¤˜"
# "AI ì›Œì»¤ ë¡œê·¸ë¥¼ í™•ì¸í•´ì¤˜"
# "OOM ì—ëŸ¬ë¥¼ í•´ê²°í•´ì¤˜"
```

**Claude Code ì¥ì :**
- âœ… `CLAUDE.md` ê·œì¹™ ìë™ ì¤€ìˆ˜
- âœ… Conventional Commits ìë™ ìƒì„±
- âœ… ì½”ë“œ ë¦¬ë·° ë° ë²„ê·¸ ì œì•ˆ
- âœ… git pushëŠ” ì‚¬ìš©ì ìŠ¹ì¸ í•„ìš” (ì•ˆì „)

**ìì„¸í•œ ë‚´ìš©:** [CLAUDE.md](CLAUDE.md) ì°¸ì¡°

---

## ğŸ¯ ê°œë°œ ë¡œë“œë§µ

### âœ… Phase 1 (ì™„ë£Œ)
- [x] í¬ë¡¤ëŸ¬ ì¸í”„ë¼ (BaseCrawler íŒ¨í„´)
- [x] MariaDB ìŠ¤í‚¤ë§ˆ ì„¤ê³„
- [x] Streamlit ëŒ€ì‹œë³´ë“œ (ìˆ˜ì‹ í•¨/ê°¤ëŸ¬ë¦¬)

### ğŸš§ Phase 2 (ì§„í–‰ ì¤‘)
- [x] LLM ìš”ì•½ (EEVE-Korean-10.8B)
- [x] TTS ìƒì„± (Kokoro-82M)
- [ ] FFmpeg ì˜ìƒ ë Œë”ë§ (NVENC)
- [ ] VRAM ê´€ë¦¬ ìµœì í™”
- [ ] ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

### ğŸ“‹ Phase 3 (ê³„íš)
- [ ] ìœ íŠœë¸Œ ì‡¼ì¸  ìë™ ì—…ë¡œë“œ
- [ ] TikTok, ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ ì§€ì›
- [ ] ê³ ê¸‰ ì˜ìƒ íš¨ê³¼ (Ken Burns, ì „í™˜)
- [ ] ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ì¡°íšŒìˆ˜, ì°¸ì—¬ìœ¨)

---

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

### ê¸°ì—¬ ì ˆì°¨

```bash
# 1. Fork & Clone
git clone https://github.com/your-username/WaggleBot.git
cd WaggleBot

# 2. ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/your-feature-name

# 3. ê°œë°œ ë° í…ŒìŠ¤íŠ¸
pytest tests/

# 4. ì»¤ë°‹
git add .
git commit -m "feat: add new feature"

# 5. Push
git push origin feature/your-feature-name

# 6. GitHubì—ì„œ Pull Request ìƒì„±
```

### ì»¤ë°‹ ë©”ì‹œì§€ ê·œì¹™

```
feat: ìƒˆ ê¸°ëŠ¥ ì¶”ê°€
fix: ë²„ê·¸ ìˆ˜ì •
docs: ë¬¸ì„œ ìˆ˜ì •
refactor: ì½”ë“œ ë¦¬íŒ©í† ë§
test: í…ŒìŠ¤íŠ¸ ì¶”ê°€/ìˆ˜ì •
chore: ë¹Œë“œ/ì„¤ì • ë³€ê²½
```

---

## ğŸ” FAQ

<details>
<summary><b>Q1: GPUê°€ ì—†ìœ¼ë©´ ì‹¤í–‰í•  ìˆ˜ ì—†ë‚˜ìš”?</b></summary>

**A:** í˜„ì¬ ë²„ì „ì€ NVIDIA GPUê°€ í•„ìˆ˜ì…ë‹ˆë‹¤. CPUë§Œìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´:
- LLM: Ollama CPU ëª¨ë“œ
- TTS: Edge-TTS (CPU)
- ì˜ìƒ: libx264 ì½”ë± (CPU, ë§¤ìš° ëŠë¦¼)

í•˜ì§€ë§Œ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. RTX 3080 Ti ê¸°ì¤€ ì˜ìƒ 1ê°œë‹¹ 2-5ë¶„ì´ì§€ë§Œ, CPUëŠ” 30ë¶„ ì´ìƒ ì†Œìš”ë©ë‹ˆë‹¤.
</details>

<details>
<summary><b>Q2: WSL ì—†ì´ Windowsì—ì„œ ì§ì ‘ ì‹¤í–‰ ê°€ëŠ¥í•œê°€ìš”?</b></summary>

**A:** ê°€ëŠ¥í•˜ì§€ë§Œ ë¹„ê¶Œì¥ì…ë‹ˆë‹¤. ì´ìœ :
- FFmpeg NVENCëŠ” Linuxì—ì„œ ë” ì•ˆì •ì 
- Python ê²½ë¡œ ì²˜ë¦¬ê°€ WSLì—ì„œ ë” ê°„ë‹¨
- Docker GPU ì§€ì›ì´ WSLì— ìµœì í™”ë¨

ì§ì ‘ ì‹¤í–‰ ì‹œ: Python 3.12 ì„¤ì¹˜ â†’ ì˜ì¡´ì„± ì„¤ì¹˜ â†’ MariaDB ë³„ë„ ì„¤ì¹˜ â†’ `.env` ì„¤ì • â†’ ê° ëª¨ë“ˆ ê°œë³„ ì‹¤í–‰
</details>

<details>
<summary><b>Q3: ë‹¤ë¥¸ ì»¤ë®¤ë‹ˆí‹° ì‚¬ì´íŠ¸ ì¶”ê°€ëŠ”?</b></summary>

**A:** `BaseCrawler`ë¥¼ ìƒì†í•˜ì—¬ êµ¬í˜„:

```python
# crawlers/yoursite.py
from crawlers.base import BaseCrawler

class YourSiteCrawler(BaseCrawler):
    def fetch_listing(self, page: int):
        # API í˜¸ì¶œ ë˜ëŠ” ìŠ¤í¬ë˜í•‘
        pass
    
    def parse_post(self, url: str):
        # íŒŒì‹± ë¡œì§
        pass
```

ìì„¸í•œ ë‚´ìš©: [arch/dev_spec.md#41-í¬ë¡¤ëŸ¬](arch/dev_spec.md#41-í¬ë¡¤ëŸ¬-í™•ì¥ì„±-íŒ¨í„´)
</details>

<details>
<summary><b>Q4: Claude Code ì—†ì´ ê°œë°œ ê°€ëŠ¥í•œê°€ìš”?</b></summary>

**A:** ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤. Claude CodeëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤. ì¼ë°˜ IDE(VS Code ë“±)ë¡œë„ ê°œë°œí•  ìˆ˜ ìˆì§€ë§Œ, ë‹¤ìŒ ê¸°ëŠ¥ì„ ë†“ì¹˜ê²Œ ë©ë‹ˆë‹¤:
- ìë™ ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±
- í”„ë¡œì íŠ¸ ê·œì¹™ ìë™ ì¤€ìˆ˜
- AI í˜ì–´ í”„ë¡œê·¸ë˜ë°

Claude Code ì‚¬ìš©ì„ ê¶Œì¥í•˜ì§€ë§Œ, í•„ìˆ˜ëŠ” ì•„ë‹™ë‹ˆë‹¤.
</details>

<details>
<summary><b>Q5: ì˜ìƒ í€„ë¦¬í‹°ë¥¼ ë†’ì´ë ¤ë©´?</b></summary>

**A:** `ai_worker/renderer.py` ìˆ˜ì •:

```python
final_video.write_videofile(
    str(output_path),
    codec='h264_nvenc',
    bitrate='8000k',      # ê¸°ë³¸ 5000k â†’ 8000k
    fps=60,               # ê¸°ë³¸ 30 â†’ 60
    preset='slow'         # ê¸°ë³¸ fast â†’ slow
)
```

ë‹¨, ë Œë”ë§ ì‹œê°„ì´ 2ë°° ì´ìƒ ì¦ê°€í•©ë‹ˆë‹¤.
</details>

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **[CLAUDE.md](CLAUDE.md)**: Claude Code ì‚¬ìš© ì‹œ ê°œë°œ ê·œì¹™
- **[arch/dev_spec.md](arch/dev_spec.md)**: ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ì„œ (1,400+ ì¤„)
    - í¬ë¡¤ëŸ¬ êµ¬í˜„ ê°€ì´ë“œ
    - AI ì›Œì»¤ VRAM ê´€ë¦¬
    - DB ìŠ¤í‚¤ë§ˆ ìƒì„¸
    - ì—ëŸ¬ í•¸ë“¤ë§
    - í…ŒìŠ¤íŠ¸ ì‘ì„±ë²•

---

## ğŸ› ë²„ê·¸ ë¦¬í¬íŠ¸ & ê¸°ëŠ¥ ì œì•ˆ

- **ë²„ê·¸ ë¦¬í¬íŠ¸**: [GitHub Issues](https://github.com/justant/WaggleBot/issues) â†’ `bug` ë¼ë²¨
- **ê¸°ëŠ¥ ì œì•ˆ**: [GitHub Issues](https://github.com/justant/WaggleBot/issues) â†’ `enhancement` ë¼ë²¨

**ë²„ê·¸ ë¦¬í¬íŠ¸ ì‹œ í¬í•¨ì‚¬í•­:**
1. í™˜ê²½ ì •ë³´ (OS, GPU, Docker ë²„ì „)
2. ì¬í˜„ ë‹¨ê³„
3. ì—ëŸ¬ ë¡œê·¸ (`docker-compose logs` ì¶œë ¥)
4. ì˜ˆìƒ ë™ì‘ vs ì‹¤ì œ ë™ì‘

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [MIT ë¼ì´ì„ ìŠ¤](LICENSE) í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

**ìš”ì•½:**
- âœ… ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥
- âœ… ìˆ˜ì • ë° ë°°í¬ ê°€ëŠ¥
- âš ï¸ ë¼ì´ì„ ìŠ¤ ë° ì €ì‘ê¶Œ ê³ ì§€ í•„ìˆ˜
- âŒ ë¬´ë³´ì¦ (AS-IS)

---

## ğŸ™ ê°ì‚¬ì˜ ë§

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

- [EEVE-Korean](https://huggingface.co/yanolja/EEVE-Korean-10.8B-v1.0) - LLM
- [Kokoro-82M](https://huggingface.co/hexgrad/Kokoro-82M) - TTS
- [FFmpeg](https://ffmpeg.org/) - ì˜ìƒ ì²˜ë¦¬
- [Streamlit](https://streamlit.io/) - ëŒ€ì‹œë³´ë“œ
- [SQLAlchemy](https://www.sqlalchemy.org/) - ORM

---

## ğŸ“ ì—°ë½ì²˜

- **í”„ë¡œì íŠ¸ ë©”ì¸í…Œì´ë„ˆ**: [@justant](https://github.com/justant)
- **GitHub Issues**: https://github.com/justant/WaggleBot/issues

---

<div align="center">

**WaggleBot**ì„ ì‚¬ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! â­

Made with â¤ï¸ by [@justant](https://github.com/justant)

</div>
