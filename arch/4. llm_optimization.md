# LLM 최적화 전체 아키텍처

## 목적
커뮤니티 게시글을 숏폼 영상 대본으로 변환할 때,
이미지 수와 텍스트 양에 따라 최적의 레이아웃을 자동 선택하고
한국어를 자연스러운 호흡 단위로 청킹하는 파이프라인.

## 레이아웃 종류
- `img_text` : 이미지 + 텍스트 혼합 (이미지 풍부할 때 우선)
- `text_only` : 텍스트만, 최대 3줄 스태킹 후 clear
- `img_only` : 이미지만 (아웃트로, 남은 이미지 소진용)

## 전체 흐름 (5 Phase)
```
[Phase 0] layout.json → settings.py → LLM 프롬프트 (설정 동기화)
[Phase 1] 이미지:텍스트 비율 분석 → 전략 결정
[Phase 2] LLM → 구어체 + 호흡 단위 줄바꿈 (의미 단위 청킹)
[Phase 3] max_chars 초과 시 어절 단위 강제 분할 (물리적 검증)
[Phase 4] 이미지 잔여량 추적 → img_text vs text_only 씬 배분
[Phase 5] layout_renderer.py → 최종 영상 렌더링
```

## 관련 파일 위치
```
config/
  layout.json      ← 제약 조건 단일 소스 (max_chars 등)
  settings.py      ← layout.json 로드 후 상수 노출
ai_worker/
  resource_analyzer.py  ← Phase 1
  llm_chunker.py        ← Phase 2
  text_validator.py     ← Phase 3
  scene_director.py     ← Phase 4
  content_processor.py  ← 전체 통합 진입점
```

# Phase 0: 설정 동기화 (Single Source of Truth)

## 핵심 원칙
`layout.json` 하나만 수정하면 `settings.py`와 LLM 프롬프트에 자동 반영.

## config/layout.json 에 추가할 constraints 블록
```json
{
  "constraints": {
    "post_title": {
      "max_chars": 40,
      "max_lines": 1,
      "description": "헤더 고정 제목 (LLM 요약 없이 원문 그대로 사용)"
    },
    "hook_text": {
      "max_chars": 50,
      "max_lines": 2,
      "description": "인트로 후킹 문장"
    },
    "body_sentence": {
      "max_chars": 45,
      "max_lines": 1,
      "description": "본문 한 줄 (img_text, text_only 공통)"
    },
    "img_text_caption": {
      "max_chars": 60,
      "max_lines": 2,
      "description": "이미지 하단 캡션"
    }
  }
}
```

> **주의:** `post_title`은 LLM이 요약하지 않음. 원문 그대로 사용.

# Phase 0: settings.py 동기화

## config/settings.py 에 추가
```python
from pathlib import Path
import json

# layout.json 로드 (단일 소스)
_layout_path = Path(__file__).parent / "layout.json"
with open(_layout_path, "r", encoding="utf-8") as f:
    _layout = json.load(f)

CONSTRAINTS = _layout["constraints"]

# 편의 상수 (코드 전역에서 임포트해서 사용)
MAX_TITLE_CHARS   = CONSTRAINTS["post_title"]["max_chars"]        # 45
MAX_HOOK_CHARS    = CONSTRAINTS["hook_text"]["max_chars"]         # 50
MAX_BODY_CHARS    = CONSTRAINTS["body_sentence"]["max_chars"]     # 45
MAX_CAPTION_CHARS = CONSTRAINTS["img_text_caption"]["max_chars"]  # 60

def get_llm_constraints_prompt() -> str:
    """LLM 프롬프트에 삽입할 제약 조건 문자열."""
    return (
        f"## 텍스트 길이 제약 (엄수 필수)\n"
        f"- 후킹 문장: 최대 {MAX_HOOK_CHARS}자\n"
        f"- 본문 한 줄: 최대 {MAX_BODY_CHARS}자\n"
        f"- 이미지 캡션: 최대 {MAX_CAPTION_CHARS}자\n"
        f"\n**초과 시 화면에서 잘립니다.**"
    )
```

## 사용 예
```python
from config.settings import MAX_BODY_CHARS, get_llm_constraints_prompt
```

# Phase 1: 자원 분석 (Resource Analyzer)

## 파일: ai_worker/resource_analyzer.py

```python
from dataclasses import dataclass
from typing import Literal

@dataclass
class ResourceProfile:
    image_count: int
    text_length: int          # 원문 글자 수
    estimated_sentences: int  # 예상 문장 수
    ratio: float              # 이미지 / 문장 비율
    strategy: Literal["img_heavy", "balanced", "text_heavy"]

def analyze_resources(post, images: list) -> ResourceProfile:
    image_count = len(images)
    text_length = len(post.content)
    estimated_sentences = max(1, text_length // 45)  # 한국어 평균 45자/문장
    ratio = image_count / estimated_sentences if estimated_sentences > 0 else 0

    if ratio >= 0.7:
        strategy = "img_heavy"   # 거의 모든 문장에 이미지
    elif ratio >= 0.3:
        strategy = "balanced"    # 중요 문장에만 이미지
    else:
        strategy = "text_heavy"  # 텍스트 위주, 이미지 절약

    return ResourceProfile(
        image_count=image_count,
        text_length=text_length,
        estimated_sentences=estimated_sentences,
        ratio=ratio,
        strategy=strategy,
    )
```

## 전략별 레이아웃 방향
| strategy | img_text | text_only | 설명 |
|---|---|---|---|
| img_heavy | 적극 사용 | 최소화 | 이미지마다 텍스트 |
| balanced | 중요 씬 | 보조 씬 | 균형 배분 |
| text_heavy | 아껴서 | 주로 사용 | 텍스트 중심 |

# Phase 2: LLM 청킹 (의미 단위 분절)

## 파일: ai_worker/llm_chunker.py

```python
from config.settings import get_llm_constraints_prompt, MAX_BODY_CHARS

def create_chunking_prompt(post_content: str, profile) -> str:
    strategy_guide = {
        "img_heavy": "각 문장 짧고 임팩트 있게. 이미지마다 한 문장.",
        "balanced":  "핵심 문장과 보조 문장을 구분해서 작성.",
        "text_heavy":"텍스트만으로 몰입되도록 자세히 작성.",
    }
    return f"""
당신은 유튜브 쇼츠 대본 작가입니다.
아래 커뮤니티 게시글을 구어체 쇼츠 대본(JSON)으로 변환하세요.

## 원문
{post_content}

## 자원 상황
- 이미지: {profile.image_count}장 / 예상 문장: {profile.estimated_sentences}개
- 전략: {profile.strategy} — {strategy_guide[profile.strategy]}

{get_llm_constraints_prompt()}

## 출력 형식 (JSON 만 출력)
{{
  "hook": "첫 3초 후킹 문장 (최대 {MAX_BODY_CHARS}자)",
  "body": ["문장1 (최대 {MAX_BODY_CHARS}자)", "문장2", ...],
  "closer": "마무리 멘트 (최대 {MAX_BODY_CHARS}자)"
}}

## 작성 규칙
1. 한 숨에 읽을 수 있는 호흡 단위로 끊기
2. 반말 구어체 (~했어, ~인데, ~ㅋㅋ)
3. 문장 중간 절대 끊지 말 것
4. {MAX_BODY_CHARS}자 초과 금지
"""
```

## Ollama 호출 (JSON 모드)
```python
response = await ollama_client.generate(
    model=settings.OLLAMA_MODEL,
    prompt=prompt,
    format="json"   # JSON 강제 → 파싱 안전
)
result = json.loads(response["response"])
```

# Phase 3: 물리적 검증 (Hard Limit Enforcement)

## 파일: ai_worker/text_validator.py

```python
from config.settings import MAX_BODY_CHARS

def smart_split_korean(text: str, max_chars: int = MAX_BODY_CHARS) -> list[str]:
    """
    한글 텍스트를 자연스러운 단위로 분할.
    우선순위: 문장부호 > 쉼표 > 접속사 > 어절 > 강제분할
    """
    if len(text) <= max_chars:
        return [text]

    chunks, remaining = [], text
    while remaining:
        if len(remaining) <= max_chars:
            chunks.append(remaining); break

        cut = False
        # 1순위: 문장 종결 (. ? !)
        for sep in ['. ', '? ', '! ']:
            pos = remaining[:max_chars].rfind(sep)
            if pos > max_chars * 0.6:
                chunks.append(remaining[:pos+1].strip())
                remaining = remaining[pos+1:].strip()
                cut = True; break

        if not cut:
            # 2순위: 쉼표
            pos = remaining[:max_chars].rfind(', ')
            if pos > max_chars * 0.6:
                chunks.append(remaining[:pos+1].strip())
                remaining = remaining[pos+1:].strip()
            else:
                # 3순위: 접속사
                best = max(
                    (remaining[:max_chars].rfind(c)
                     for c in ['근데 ','그래서 ','그런데 ','하지만 ','그리고 ']),
                    default=-1
                )
                if best > max_chars * 0.5:
                    chunks.append(remaining[:best].strip())
                    remaining = remaining[best:].strip()
                else:
                    # 4순위: 어절(띄어쓰기)
                    pos = remaining[:max_chars].rfind(' ')
                    if pos > 0:
                        chunks.append(remaining[:pos].strip())
                        remaining = remaining[pos:].strip()
                    else:
                        chunks.append(remaining[:max_chars])
                        remaining = remaining[max_chars:]
    return chunks


def validate_and_fix(llm_output: dict) -> dict:
    """LLM 출력 검증 및 초과 문장 분할 보정."""
    for key in ["hook", "closer"]:
        if len(llm_output[key]) > MAX_BODY_CHARS:
            llm_output[key] = smart_split_korean(llm_output[key])[0]

    fixed = []
    for sent in llm_output["body"]:
        fixed.extend(smart_split_korean(sent) if len(sent) > MAX_BODY_CHARS else [sent])
    llm_output["body"] = fixed
    return llm_output
```

# Phase 4: 씬 배분 알고리즘 (Scene Director)

## 파일: ai_worker/scene_director.py

```python
from dataclasses import dataclass, field
from pathlib import Path
from typing import Literal

@dataclass
class SceneDecision:
    type: Literal["intro", "img_text", "text_only", "outro"]
    text_lines: list[str]
    image_path: Path | None
    text_only_stack: int = 1  # text_only일 때 쌓는 줄 수 (1~3)


class SceneDirector:
    def __init__(self, profile, images: list[Path], script: dict):
        self.profile = profile
        self.images  = list(images)   # 소모 추적용 복사본
        self.script  = script
        self.scenes  = []

    def direct(self) -> list[SceneDecision]:
        # Intro
        self.scenes.append(SceneDecision("intro", [self.script["hook"]], None))

        body = list(self.script["body"])
        while body:
            if self.images:
                self._add_img_text(body)
            else:
                self._add_text_only(body)

        # Outro (남은 이미지 소진)
        if self.images:
            self.scenes.append(SceneDecision(
                "outro", [self.script["closer"]], self.images.pop(0)
            ))
        return self.scenes

    def _add_img_text(self, body: list):
        self.scenes.append(SceneDecision(
            "img_text", [body.pop(0)], self.images.pop(0)
        ))

    def _add_text_only(self, body: list):
        n = self._decide_stack(body)
        lines = [body.pop(0) for _ in range(min(n, len(body)))]
        self.scenes.append(SceneDecision("text_only", lines, None, len(lines)))

    def _decide_stack(self, remaining: list) -> int:
        base = {"img_heavy": 1, "balanced": 2, "text_heavy": 3}[self.profile.strategy]
        if len(remaining) <= 2:
            return min(len(remaining), 2)
        # 반전/결론 키워드 → 단독 강조
        keywords = ["반전", "충격", "결과", "결론", "사실"]
        if any(kw in remaining[0] for kw in keywords):
            return 1
        return base
```

## 씬 흐름 요약
```
intro(hook) → [img_text | text_only] × N → outro(closer + 남은이미지)
```
- 이미지 있으면 → `img_text` 우선
- 이미지 소진 후 → `text_only` (전략에 따라 1~3줄 스태킹)
- 마지막 이미지 남으면 → `outro` 1장

# Phase 5: 전체 통합 진입점

## 파일: ai_worker/content_processor.py

```python
import collections
import logging
from pathlib import Path

from ai_worker.resource_analyzer import analyze_resources
from ai_worker.llm_chunker       import chunk_with_llm
from ai_worker.text_validator    import validate_and_fix
from ai_worker.scene_director    import SceneDirector, SceneDecision

logger = logging.getLogger(__name__)

async def process_content(post, images: list[Path]) -> list[SceneDecision]:
    """콘텐츠 처리 전체 파이프라인."""

    # Phase 1: 자원 분석
    profile = analyze_resources(post, images)
    logger.info(f"전략={profile.strategy} 이미지={profile.image_count} 문장≈{profile.estimated_sentences}")

    # Phase 2: LLM 청킹 (의미 단위)
    llm_output = await chunk_with_llm(post.content, profile)

    # Phase 3: 물리적 검증 (max_chars 보정)
    script = validate_and_fix(llm_output)
    logger.info(f"대본: hook + body({len(script['body'])}줄) + closer")

    # Phase 4: 씬 배분
    director = SceneDirector(profile, images, script)
    scenes   = director.direct()
    counter  = collections.Counter(s.type for s in scenes)
    logger.info(f"씬 구성: {len(scenes)}개 {dict(counter)}")

    return scenes
```

---

## 한국어 청킹 라이브러리 추천 요약

| 방법 | 정확도 | 속도 | 의존성 | 추천도 |
|---|---|---|---|---|
| KoNLPy (형태소) | ★★★ | 느림 | Java 필요 | 정확도 중시 시 |
| `smart_split_korean()` (regex) | ★★ | 빠름 | 없음 | **⭐ 실용 추천** |
| LangChain CharacterTextSplitter | ★ | 중간 | langchain | 한국어 비특화 |

→ `smart_split_korean()` (Phase 3) 으로 충분. 운영 안정 후 KoNLPy 교체 고려.

---

## 제목(post_title) 처리 원칙
- LLM 요약 **하지 않음**
- `post.title` 원문을 그대로 사용
- `MAX_TITLE_CHARS(40자)` 초과 시 말줄임(`…`) 처리만 허용

```python
title = post.title[:MAX_TITLE_CHARS-1] + "…" if len(post.title) > MAX_TITLE_CHARS else post.title
```






