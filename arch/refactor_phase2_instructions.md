# WaggleBot êµ¬ì¡° ê°œì„  Phase 2 â€” Task 6~12

> **ì „ì œ**: Phase 1 (Task 1~5) ì™„ë£Œ í›„ ì§„í–‰
> **ëª©ì **: í™•ì¥ì„±Â·ìœ ì§€ë³´ìˆ˜ì„±Â·ì•ˆì •ì„± ê°•í™”
> **í•„ë…**: `CLAUDE.md` ì½”ë”© ê·œì¹™ ì¤€ìˆ˜

---

## ëª©ì°¨

| Task | ì˜ì—­ | ì‹¬ê°ë„ | ì‘ì—…ëŸ‰ |
|:---:|---|:---:|:---:|
| 6 | Content.get_script() ìˆœí™˜ import ì œê±° | ğŸ”´ ëŸ°íƒ€ì„ ìœ„í—˜ | ì†Œ |
| 7 | settings.py ë„ë©”ì¸ë³„ ë¶„ë¦¬ | ğŸŸ¡ ë¹„ëŒ€í™” | ì¤‘ |
| 8 | analytics ëª¨ë“ˆ â€” Ollama ì§ì ‘ í˜¸ì¶œ ì œê±° | ğŸŸ¡ ì¼ê´€ì„± | ì†Œ |
| 9 | plugin_manager.py ë‹¨ìˆœí™” | ğŸŸ¡ ê³¼ì„¤ê³„ | ì†Œ |
| 10 | arch/ ë¬¸ì„œ ì •ë¦¬ (ì£½ì€ ìŠ¤í™ ì •ë¦¬) | ğŸŸ¡ í˜¼ë€ ìœ ë°œ | ì†Œ |
| 11 | Uploader í™•ì¥ì„± ê°œì„  | ğŸŸ¢ í–¥í›„ ëŒ€ë¹„ | ì¤‘ |
| 12 | ì—ëŸ¬ ì²˜ë¦¬ ì¼ê´€ì„± í™•ë³´ | ğŸŸ¢ ì•ˆì •ì„± | ì¤‘ |

---

## Task 6: Content.get_script() ìˆœí™˜ import ì œê±°

### ë¬¸ì œ

`db/models.py`ì˜ `Content.get_script()` ë©”ì„œë“œê°€ **í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ai_workerë¥¼ import**í•œë‹¤:

```python
# db/models.py â€” Content í´ë˜ìŠ¤ ì•ˆ
def get_script(self) -> "ScriptData | None":
    ...
    from ai_worker.llm import ScriptData   # â† ìˆœí™˜ import ìœ„í—˜
    ...
```

DB ëª¨ë¸(í•˜ìœ„ ë ˆì´ì–´)ì´ AI ì›Œì»¤(ìƒìœ„ ë ˆì´ì–´)ë¥¼ ì°¸ì¡°í•˜ëŠ” **ì—­ë°©í–¥ ì˜ì¡´**ì´ë‹¤.
í˜„ì¬ëŠ” lazy importë¼ ë‹¹ì¥ ì—ëŸ¬ëŠ” ì•ˆ ë‚˜ì§€ë§Œ:
- `ai_worker/` êµ¬ì¡° ë³€ê²½ ì‹œ(ì˜ˆ: `ai_worker_restructure.md` ê³„íš) ê²½ë¡œê°€ ë°”ë€Œë©´ ì¦‰ì‹œ ê¹¨ì§
- ëª¨ë“ˆ ê°„ ì˜ì¡´ì„± ê·¸ë˜í”„ê°€ ìˆœí™˜ â†’ í…ŒìŠ¤íŠ¸Â·ë¦¬íŒ©í„°ë§ ë‚œì´ë„ ìƒìŠ¹
- `db/models.py`ë¥¼ ìˆ˜ì • ì—†ì´ ë‹¨ë… í…ŒìŠ¤íŠ¸ ë¶ˆê°€ëŠ¥

### í•´ê²°

`ScriptData`ë¥¼ `db/` ë˜ëŠ” ê³µìœ  ë ˆì´ì–´ë¡œ ì´ë™í•œë‹¤.

#### 6-1. `db/models.py`ì— `ScriptData` ì •ì˜ ì´ë™

í˜„ì¬ `ai_worker/llm.py`ì— ìˆëŠ” `ScriptData` dataclassë¥¼ `db/models.py`ë¡œ ì´ë™í•˜ë¼.

**`db/models.py` í•˜ë‹¨ì— ì¶”ê°€:**

```python
import json as _json
from dataclasses import dataclass, field


@dataclass
class ScriptData:
    """êµ¬ì¡°í™”ëœ ì‡¼ì¸  ëŒ€ë³¸ ë°ì´í„°.

    ai_worker/llm.pyì—ì„œ ìƒì„±í•˜ê³  Content.summary_textì— JSONìœ¼ë¡œ ì €ì¥.
    """
    hook: str
    body: list[str]
    closer: str
    title_suggestion: str = ""
    tags: list[str] = field(default_factory=list)
    mood: str = "funny"

    def to_json(self) -> str:
        return _json.dumps(
            {
                "hook": self.hook,
                "body": self.body,
                "closer": self.closer,
                "title_suggestion": self.title_suggestion,
                "tags": self.tags,
                "mood": self.mood,
            },
            ensure_ascii=False,
        )

    @classmethod
    def from_json(cls, raw: str) -> "ScriptData":
        data = _json.loads(raw)
        return cls(
            hook=data["hook"],
            body=data["body"],
            closer=data["closer"],
            title_suggestion=data.get("title_suggestion", ""),
            tags=data.get("tags", []),
            mood=data.get("mood", "funny"),
        )
```

#### 6-2. Content.get_script()ì—ì„œ lazy import ì œê±°

```python
# Before
def get_script(self) -> "ScriptData | None":
    from ai_worker.llm import ScriptData
    ...

# After
def get_script(self) -> "ScriptData | None":
    # ScriptDataê°€ ê°™ì€ íŒŒì¼ì— ìˆìœ¼ë¯€ë¡œ import ë¶ˆí•„ìš”
    ...
```

#### 6-3. ai_worker/llm.pyì—ì„œ ScriptDataë¥¼ re-export

ê¸°ì¡´ì— `from ai_worker.llm import ScriptData`ë¡œ ì‚¬ìš©í•˜ëŠ” ì½”ë“œê°€ ë§ìœ¼ë¯€ë¡œ,
`ai_worker/llm.py`ì—ì„œ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë¼:

```python
# ai_worker/llm.py ìƒë‹¨
from db.models import ScriptData  # re-export (ê¸°ì¡´ import í˜¸í™˜)
```

ì›ë³¸ ScriptData ì •ì˜ ì½”ë“œëŠ” `ai_worker/llm.py`ì—ì„œ **ì‚­ì œ**í•˜ë¼.

#### 6-4. ì°¸ì¡° ê²€ì¦

```bash
grep -rn "from ai_worker.llm import ScriptData\|from ai_worker.llm.client import ScriptData" --include="*.py" .
```

ê²°ê³¼ì— ë‚˜ì˜¤ëŠ” íŒŒì¼ë“¤ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸. `db/models.py`ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ë„ë¡ ì ì§„ êµì²´ ê°€ëŠ¥í•˜ì§€ë§Œ, re-exportë¡œ ë‹¹ì¥ì€ í˜¸í™˜ëœë‹¤.

---

## Task 7: settings.py ë„ë©”ì¸ë³„ ë¶„ë¦¬

### ë¬¸ì œ

Task 3ì—ì„œ í¬ë¡¤ëŸ¬ ì„¹ì…˜ì„ ì œê±°í•´ë„ `config/settings.py`ëŠ” ì—¬ì „íˆ **200ì¤„ ì´ìƒ**ì´ë©°, ì „í˜€ ê´€ë ¨ ì—†ëŠ” ë„ë©”ì¸ì´ í˜¼ì¬í•œë‹¤:

- í¬ë¡¤ëŸ¬ ê³µí†µ ì„¤ì • (USER_AGENTS, REQUEST_HEADERS)
- AI Worker ì„¤ì • (OLLAMA_HOST, GPU ê´€ë ¨)
- TTS ì„¤ì • (Fish Speech, VOICE_PRESETS, EMOTION_TAGS)
- ëª¨ë‹ˆí„°ë§ ì„¤ì • (GPU_TEMP, DISK_USAGE)
- ë ˆì´ì•„ì›ƒ ì œì•½ (layout.json ë¡œë“œ)
- í”Œë«í¼ ì¸ì¦ (PLATFORM_CREDENTIAL_FIELDS)
- ì´ë©”ì¼/ìŠ¬ë™ ì•Œë¦¼

í•œ ì„¤ì •ì„ ìˆ˜ì •í•˜ë ¤ë©´ ì „ì²´ íŒŒì¼ì„ ì½ì–´ì•¼ í•˜ê³ , ì¶©ëŒ ìœ„í—˜ì´ ë†’ë‹¤.

### í•´ê²°

`config/settings.py`ë¥¼ ë©”ì¸ í—ˆë¸Œë¡œ ë‘ë˜, ë„ë©”ì¸ë³„ ì„œë¸Œëª¨ë“ˆë¡œ ë¶„ë¦¬í•œë‹¤.

#### 7-1. íŒŒì¼ êµ¬ì¡°

```
config/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ settings.py          # ê³µí†µ ì„¤ì • (DATABASE_URL ë“±) + ê° ì„œë¸Œëª¨ë“ˆ re-export
â”œâ”€â”€ crawler.py           # í¬ë¡¤ëŸ¬ ê³µí†µ ì„¤ì • (USER_AGENTS, REQUEST_HEADERS ë“±)
â”œâ”€â”€ ai_worker.py         # AI Worker + TTS + ë ˆì´ì•„ì›ƒ ì œì•½
â”œâ”€â”€ monitoring.py        # ëª¨ë‹ˆí„°ë§ ì„ê³„ê°’ + ì•Œë¦¼ ì„¤ì •
â”œâ”€â”€ pipeline.json        # (ê¸°ì¡´ ìœ ì§€)
â”œâ”€â”€ layout.json          # (ê¸°ì¡´ ìœ ì§€)
â””â”€â”€ feedback_config.json # (ëŸ°íƒ€ì„ ìƒì„±)
```

#### 7-2. `config/crawler.py` ìƒì„±

`settings.py`ì—ì„œ ì•„ë˜ í•­ëª©ì„ ì´ë™:

```python
"""í¬ë¡¤ëŸ¬ ê³µí†µ ì„¤ì •."""
import os

USER_AGENTS: list[str] = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...",
    # ... ê¸°ì¡´ ëª©ë¡ ê·¸ëŒ€ë¡œ
]

REQUEST_HEADERS: dict[str, str] = {
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
}

REQUEST_TIMEOUT: int = int(os.getenv("REQUEST_TIMEOUT", "15"))
ENABLED_CRAWLERS: list[str] = os.getenv("ENABLED_CRAWLERS", "nate_pann").split(",")
```

#### 7-3. `config/monitoring.py` ìƒì„±

`settings.py`ì—ì„œ ì•„ë˜ í•­ëª©ì„ ì´ë™:

```python
"""ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •."""
import os

MONITORING_ENABLED = os.getenv("MONITORING_ENABLED", "true").lower() == "true"
HEALTH_CHECK_INTERVAL = int(os.getenv("HEALTH_CHECK_INTERVAL", "300"))

# ì„ê³„ê°’
GPU_TEMP_WARNING = int(os.getenv("GPU_TEMP_WARNING", "75"))
GPU_TEMP_CRITICAL = int(os.getenv("GPU_TEMP_CRITICAL", "80"))
DISK_USAGE_WARNING = int(os.getenv("DISK_USAGE_WARNING", "80"))
DISK_USAGE_CRITICAL = int(os.getenv("DISK_USAGE_CRITICAL", "90"))
MEMORY_USAGE_WARNING = int(os.getenv("MEMORY_USAGE_WARNING", "85"))
MEMORY_USAGE_CRITICAL = int(os.getenv("MEMORY_USAGE_CRITICAL", "95"))

# ì´ë©”ì¼ ì•Œë¦¼
EMAIL_ALERTS_ENABLED = os.getenv("EMAIL_ALERTS_ENABLED", "false").lower() == "true"
SMTP_HOST = os.getenv("SMTP_HOST", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USER = os.getenv("SMTP_USER", "")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD", "")
ALERT_EMAIL_TO = os.getenv("ALERT_EMAIL_TO", "").split(",") if os.getenv("ALERT_EMAIL_TO") else []

# ìŠ¬ë™ ì•Œë¦¼
SLACK_ALERTS_ENABLED = os.getenv("SLACK_ALERTS_ENABLED", "false").lower() == "true"
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL", "")
```

#### 7-4. settings.pyë¥¼ í—ˆë¸Œë¡œ ìœ ì§€ (í˜¸í™˜ì„±)

ê¸°ì¡´ì— `from config.settings import USER_AGENTS`ë¡œ importí•˜ëŠ” ì½”ë“œê°€ ë§ìœ¼ë¯€ë¡œ,
`settings.py`ì—ì„œ re-export í•˜ë¼:

```python
# config/settings.py ìƒë‹¨
# --- re-export (ê¸°ì¡´ import ê²½ë¡œ í˜¸í™˜) ---
from config.crawler import (
    USER_AGENTS, REQUEST_HEADERS, REQUEST_TIMEOUT, ENABLED_CRAWLERS,
)
from config.monitoring import (
    MONITORING_ENABLED, HEALTH_CHECK_INTERVAL,
    GPU_TEMP_WARNING, GPU_TEMP_CRITICAL,
    # ... ë‚˜ë¨¸ì§€
)
```

ì´ë ‡ê²Œ í•˜ë©´ ê¸°ì¡´ ì½”ë“œëŠ” ìˆ˜ì • ì—†ì´ ë™ì‘í•˜ë©´ì„œ, ìƒˆ ì½”ë“œëŠ” `from config.crawler import USER_AGENTS`ì²˜ëŸ¼ ì •í™•í•œ ê²½ë¡œë¡œ import ê°€ëŠ¥.

#### 7-5. ì ì§„ ë§ˆì´ê·¸ë ˆì´ì…˜

**ì´ë²ˆ Taskì—ì„œëŠ” íŒŒì¼ ë¶„ë¦¬ + re-exportë§Œ ìˆ˜í–‰.**
ê° ëª¨ë“ˆì˜ import ê²½ë¡œë¥¼ ì •í™•í•œ ì„œë¸Œëª¨ë“ˆë¡œ ë°”ê¾¸ëŠ” ê²ƒì€ í–¥í›„ ì ì§„ì ìœ¼ë¡œ ì§„í–‰.

---

## Task 8: analytics ëª¨ë“ˆ â€” Ollama ì§ì ‘ í˜¸ì¶œ ì œê±°

### ë¬¸ì œ

`analytics/feedback.py`ì˜ `generate_structured_insights()`ê°€ **requestsë¡œ Ollama APIë¥¼ ì§ì ‘ í˜¸ì¶œ**í•œë‹¤:

```python
# analytics/feedback.py
resp = requests.post(
    f"{get_ollama_host()}/api/generate",
    json={"model": model, "prompt": prompt, ...},
    timeout=120,
)
```

í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ Ollama í˜¸ì¶œì€ `ai_worker/llm.py`ê°€ ë‹´ë‹¹í•˜ëŠ”ë°, `analytics/`ê°€ ë…ìì ìœ¼ë¡œ HTTPë¥¼ ìœë‹¤.
ì´ëŠ”:
- Ollama í˜¸ì¶œ ë°©ì‹ ë³€ê²½ ì‹œ 2ê³³ì„ ë™ì‹œ ìˆ˜ì •í•´ì•¼ í•¨
- LLM í˜¸ì¶œ ë¡œê¹…(`llm_logger.py`)ì„ ìš°íšŒ
- GPU ë§¤ë‹ˆì €(`gpu_manager.py`)ë¥¼ ìš°íšŒ â†’ VRAM ì¶©ëŒ ê°€ëŠ¥

### í•´ê²°

#### 8-1. `ai_worker/llm.py`ì— ë²”ìš© LLM í˜¸ì¶œ í•¨ìˆ˜ ì¶”ê°€

í˜„ì¬ `generate_script()`ëŠ” ëŒ€ë³¸ íŠ¹í™” í•¨ìˆ˜ì´ë‹¤. ë²”ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ëŠ” í•¨ìˆ˜ë¥¼ ì¶”ê°€í•˜ë¼:

```python
# ai_worker/llm.pyì— ì¶”ê°€

def call_ollama_raw(
    prompt: str,
    model: str | None = None,
    max_tokens: int = 512,
    temperature: float = 0.5,
) -> str:
    """ë²”ìš© Ollama API í˜¸ì¶œ. JSON íŒŒì‹± ì—†ì´ ì›ì‹œ ì‘ë‹µ ë°˜í™˜.

    Args:
        prompt: í”„ë¡¬í”„íŠ¸ ì „ì²´ í…ìŠ¤íŠ¸
        model: Ollama ëª¨ë¸ëª… (Noneì´ë©´ ê¸°ë³¸ê°’)
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
        temperature: ìƒ˜í”Œë§ ì˜¨ë„

    Returns:
        LLM ì›ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    import requests as _requests
    _model = model or OLLAMA_MODEL

    resp = _requests.post(
        f"{get_ollama_host()}/api/generate",
        json={
            "model": _model,
            "prompt": prompt,
            "stream": False,
            "options": {"num_predict": max_tokens, "temperature": temperature},
        },
        timeout=120,
    )
    resp.raise_for_status()
    return resp.json().get("response", "").strip()
```

#### 8-2. `analytics/feedback.py` ìˆ˜ì •

ì§ì ‘ HTTP í˜¸ì¶œì„ `call_ollama_raw()`ë¡œ êµì²´í•˜ë¼:

```python
# Before
resp = requests.post(
    f"{get_ollama_host()}/api/generate",
    json={...},
    timeout=120,
)
resp.raise_for_status()
raw = resp.json().get("response", "").strip()

# After
from ai_worker.llm import call_ollama_raw

raw = call_ollama_raw(
    prompt=prompt,
    model=model,
    max_tokens=512,
    temperature=0.5,
)
```

#### 8-3. feedback.pyì—ì„œ ë¶ˆí•„ìš”í•œ import ì œê±°

```python
# ì‚­ì œ
import requests
from config.settings import get_ollama_host, OLLAMA_MODEL
```

`OLLAMA_MODEL`ì€ `call_ollama_raw` ë‚´ë¶€ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ feedback.pyì—ì„œ ë¶ˆí•„ìš”.

---

## Task 9: plugin_manager.py ë‹¨ìˆœí™”

### ë¬¸ì œ

`plugin_manager.py`ëŠ” 267ì¤„ì´ë©° ê³¼ì„¤ê³„ëœ ë¶€ë¶„ì´ ìˆë‹¤:

1. **`auto_discover()`** (50ì¤„): ëª¨ë“  í¬ë¡¤ëŸ¬ê°€ ì´ë¯¸ `@CrawlerRegistry.register` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, "ë¯¸ë“±ë¡ í¬ë¡¤ëŸ¬ ë°œê²¬" ê²½ê³ ë¥¼ ì¶œë ¥í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ì—­í• . ì‹¤ì§ˆì  ê°€ì¹˜ ì—†ìŒ.
2. **`unregister()`**: ì‚¬ìš©ì²˜ ì—†ìŒ (í…ŒìŠ¤íŠ¸ì—ì„œë„ ì•ˆ ì”€)
3. **`clear()`**: "í…ŒìŠ¤íŠ¸ìš©"ì´ë¼ ëª…ì‹œí–ˆìœ¼ë‚˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ
4. **ëª¨ë“ˆ ë ˆë²¨ í¸ì˜ í•¨ìˆ˜ 3ê°œ** (`get_crawler()`, `list_crawlers()`, `auto_discover()`): `CrawlerRegistry` í´ë˜ìŠ¤ ë©”ì„œë“œì™€ ì™„ì „ ì¤‘ë³µ

### í•´ê²°

#### 9-1. ì‚­ì œí•  ë©”ì„œë“œ/í•¨ìˆ˜

- `CrawlerRegistry.auto_discover()` â€” ì‚­ì œ
- `CrawlerRegistry.unregister()` â€” ì‚­ì œ
- `CrawlerRegistry.clear()` â€” ì‚­ì œ
- ëª¨ë“ˆ ë ˆë²¨ `auto_discover()` í•¨ìˆ˜ â€” ì‚­ì œ

#### 9-2. ìœ ì§€í•  ê²ƒ

- `CrawlerRegistry.register()` â€” í•µì‹¬ ë°ì½”ë ˆì´í„°
- `CrawlerRegistry.get_crawler()` â€” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
- `CrawlerRegistry.list_crawlers()` â€” ëª©ë¡ ì¡°íšŒ
- `CrawlerRegistry.get_enabled_crawlers()` â€” í™œì„± ëª©ë¡
- `CrawlerRegistry.is_registered()` â€” ë“±ë¡ í™•ì¸
- ëª¨ë“ˆ ë ˆë²¨ `get_crawler()`, `list_crawlers()` â€” í¸ì˜ í•¨ìˆ˜ (ì‚¬ìš©ì²˜ ìˆì„ ìˆ˜ ìˆìŒ)

#### 9-3. ì‚­ì œ ì „ ì°¸ì¡° í™•ì¸

```bash
grep -rn "auto_discover\|unregister\|\.clear()" --include="*.py" .
```

`main.py`ë‚˜ ë‹¤ë¥¸ ê³³ì—ì„œ `auto_discover()`ë¥¼ í˜¸ì¶œí•˜ê³  ìˆìœ¼ë©´ í•´ë‹¹ í˜¸ì¶œë„ ì œê±°í•˜ë¼.

---

## Task 10: arch/ ë¬¸ì„œ ì •ë¦¬

### ë¬¸ì œ

`arch/` ë””ë ‰í† ë¦¬ì— ê³¼ê±° ìŠ¤í™ ë¬¸ì„œê°€ ë‚¨ì•„ìˆìœ¼ë©°, ì¼ë¶€ëŠ” í˜„ì¬ ì½”ë“œì™€ ë¶ˆì¼ì¹˜í•œë‹¤:

| íŒŒì¼ | ìƒíƒœ |
|---|---|
| `arch/1. dev_spec.md` | Phase 3 ì´ì „ ìŠ¤í™ â€” í˜„ì¬ ì½”ë“œì™€ ë‹¤ìˆ˜ ë¶ˆì¼ì¹˜ |
| `arch/2. next_spec_by_claude.md` | Phase 3 ë¡œë“œë§µ â€” Phase 3A/3B/3C ì™„ë£Œ í‘œì‹œë¨ |
| `arch/3. renderer_from_figma.md` | "Merged to Main" ëª…ì‹œ â€” ì™„ë£Œëœ ë¬¸ì„œ |
| `arch/4. llm_optimization.md` | 5-Phase íŒŒì´í”„ë¼ì¸ ê³„íš â€” `use_content_processor: false`ë¡œ ë¹„í™œì„± |
| `arch/5. tts_inhancement.md` | Fish Speech êµì²´ ê³„íš â€” ë¯¸ì™„ì„± (ì•„ì§ edge-tts ì‚¬ìš© ì¤‘) |
| `arch/ai_worker_restructure.md` | ë””ë ‰í† ë¦¬ ì¬í¸ ê³„íš â€” ë¯¸ì‹¤í–‰ |

### í•´ê²°

#### 10-1. ì™„ë£Œëœ ìŠ¤í™ì„ `arch/done/`ìœ¼ë¡œ ì´ë™

```bash
mkdir -p arch/done
mv "arch/1. dev_spec.md" arch/done/
mv "arch/2. next_spec_by_claude.md" arch/done/
mv "arch/3. renderer_from_figma.md" arch/done/
```

#### 10-2. ë¯¸ì‹¤í–‰ ìŠ¤í™ì— ìƒíƒœ í‘œì‹œ ì¶”ê°€

ì•„ë˜ íŒŒì¼ì˜ **ë§¨ ì²« ì¤„**ì— ìƒíƒœ ë°°ë„ˆë¥¼ ì¶”ê°€í•˜ë¼:

**`arch/4. llm_optimization.md`:**
```markdown
> âš ï¸ **ë¬¸ì„œ ìƒíƒœ**: ê³„íš ìˆ˜ë¦½ ì™„ë£Œ, ë¯¸ì‹¤í–‰. `config/pipeline.json`ì˜ `use_content_processor`ê°€ `false`ì¸ ë™ì•ˆì€ ë¹„í™œì„±.
```

**`arch/5. tts_inhancement.md`:**
```markdown
> âš ï¸ **ë¬¸ì„œ ìƒíƒœ**: ê³„íš ìˆ˜ë¦½ ì™„ë£Œ, ë¯¸ì‹¤í–‰. í˜„ì¬ edge-tts ì‚¬ìš© ì¤‘. Fish Speech ë„ì… ì‹œ ì´ ë¬¸ì„œ ì°¸ì¡°.
```

**`arch/ai_worker_restructure.md`:**
```markdown
> âš ï¸ **ë¬¸ì„œ ìƒíƒœ**: ê³„íš ìˆ˜ë¦½ ì™„ë£Œ, ë¯¸ì‹¤í–‰. ai_worker/ íŒŒì¼ì´ ì¦ê°€í•˜ë©´ ì´ ê³„íšì— ë”°ë¼ ì¬í¸.
```

#### 10-3. CLAUDE.md ì—…ë°ì´íŠ¸

`CLAUDE.md`ì˜ "Phase 3 ê°œë°œ í˜„í™©" ì„¹ì…˜ ì•„ë˜ì— ì¶”ê°€:

```markdown
### arch/ ë¬¸ì„œ ê°€ì´ë“œ
- `arch/done/` â€” ì™„ë£Œëœ ê³¼ê±° ìŠ¤í™ (ì°¸ê³ ìš©)
- `arch/4. llm_optimization.md` â€” 5-Phase íŒŒì´í”„ë¼ì¸ (ë¯¸ì‹¤í–‰, use_content_processor=false)
- `arch/5. tts_inhancement.md` â€” Fish Speech TTS êµì²´ (ë¯¸ì‹¤í–‰)
- `arch/ai_worker_restructure.md` â€” ai_worker ë””ë ‰í† ë¦¬ ì¬í¸ (ë¯¸ì‹¤í–‰)
```

---

## Task 11: Uploader í™•ì¥ì„± ê°œì„ 

### ë¬¸ì œ

`uploaders/base.py`ì˜ `BaseUploader`ë¥¼ ìƒì†í•˜ë©´ ìƒˆ í”Œë«í¼ì„ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤ê³  ë¬¸ì„œì— ëª…ì‹œë˜ì–´ ìˆì§€ë§Œ, ì‹¤ì œë¡œ **ì—…ë¡œë” ìë™ ë“±ë¡ ë©”ì»¤ë‹ˆì¦˜ì´ ì—†ë‹¤**.

í˜„ì¬ `uploaders/uploader.py`ì—ì„œ YouTube ì—…ë¡œë”ë¥¼ **í•˜ë“œì½”ë”©**ìœ¼ë¡œ í˜¸ì¶œí•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
í¬ë¡¤ëŸ¬ëŠ” `CrawlerRegistry`ë¡œ í”ŒëŸ¬ê·¸ì¸ ë“±ë¡ì´ ë˜ëŠ”ë°, ì—…ë¡œë”ì—ëŠ” ì´ êµ¬ì¡°ê°€ ì—†ë‹¤.

### í•´ê²°

#### 11-1. UploaderRegistry íŒ¨í„´ ë„ì…

`uploaders/base.py`ì— ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì¶”ê°€í•˜ë¼:

```python
# uploaders/base.py

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, Type

class BaseUploader(ABC):
    platform: str = ""

    @abstractmethod
    def validate_credentials(self) -> bool:
        """ì¸ì¦ ì •ë³´ ìœ íš¨ì„± ê²€ì¦."""

    @abstractmethod
    def upload(self, video_path: Path, metadata: dict) -> dict:
        """ì˜ìƒ ì—…ë¡œë“œ. ë°˜í™˜: {"url": ..., "video_id": ..., "platform": ...}"""


class UploaderRegistry:
    """ì—…ë¡œë” í”ŒëŸ¬ê·¸ì¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬."""

    _uploaders: Dict[str, Type[BaseUploader]] = {}

    @classmethod
    def register(cls, platform: str):
        """ì—…ë¡œë” ë“±ë¡ ë°ì½”ë ˆì´í„°."""
        def decorator(uploader_class: Type[BaseUploader]):
            cls._uploaders[platform] = uploader_class
            return uploader_class
        return decorator

    @classmethod
    def get_uploader(cls, platform: str) -> BaseUploader:
        if platform not in cls._uploaders:
            available = ", ".join(cls._uploaders.keys())
            raise ValueError(
                f"Unknown platform: '{platform}'. Available: {available}"
            )
        return cls._uploaders[platform]()

    @classmethod
    def list_platforms(cls) -> list[str]:
        return list(cls._uploaders.keys())
```

#### 11-2. YouTube ì—…ë¡œë”ì— ë°ì½”ë ˆì´í„° ì ìš©

```python
# uploaders/youtube.py
from uploaders.base import BaseUploader, UploaderRegistry

@UploaderRegistry.register("youtube")
class YouTubeUploader(BaseUploader):
    platform = "youtube"
    ...
```

#### 11-3. `uploaders/uploader.py` ìˆ˜ì •

`upload_post()` í•¨ìˆ˜ì—ì„œ í•˜ë“œì½”ë”© ëŒ€ì‹  ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‚¬ìš©:

```python
# Before (ì¶”ì •)
from uploaders.youtube import YouTubeUploader
uploader = YouTubeUploader()

# After
from uploaders.base import UploaderRegistry

def upload_post(post, content, platforms: list[str]) -> dict:
    results = {}
    for platform in platforms:
        uploader = UploaderRegistry.get_uploader(platform)
        if uploader.validate_credentials():
            results[platform] = uploader.upload(video_path, metadata)
    return results
```

#### 11-4. ADDING_UPLOADER.md ìƒì„±

`uploaders/ADDING_UPLOADER.md`ë¥¼ `crawlers/ADDING_CRAWLER.md`ì™€ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ì‘ì„±í•˜ë¼:

```markdown
# ì—…ë¡œë” ì¶”ê°€ ê°€ì´ë“œ

## êµ¬í˜„ ë‹¨ê³„

### 1. ì—…ë¡œë” íŒŒì¼ ìƒì„±

`uploaders/tiktok.py` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

\```python
from pathlib import Path
from uploaders.base import BaseUploader, UploaderRegistry

@UploaderRegistry.register("tiktok")
class TikTokUploader(BaseUploader):
    platform = "tiktok"

    def validate_credentials(self) -> bool:
        ...

    def upload(self, video_path: Path, metadata: dict) -> dict:
        ...
\```

### 2. pipeline.json í™œì„±í™”

\```json
{"upload_platforms": "[\"youtube\", \"tiktok\"]"}
\```
```

---

## Task 12: ì—ëŸ¬ ì²˜ë¦¬ ì¼ê´€ì„± í™•ë³´

### ë¬¸ì œ

í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´ì´ ì¼ê´€ë˜ì§€ ì•ŠëŠ”ë‹¤:

#### (A) í¬ë¡¤ëŸ¬: except ë²”ìœ„ê°€ ë„ˆë¬´ ë„“ìŒ

```python
# í˜„ì¬ â€” ëª¨ë“  ì˜ˆì™¸ë¥¼ ì¡ì•„ì„œ ë¡œê·¸ë§Œ ì°ê³  continue
except Exception:
    log.exception("Failed to parse %s", item["url"])
    continue
```

ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬, íŒŒì‹± ì—ëŸ¬, DB ì—ëŸ¬ê°€ ì „ë¶€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ë¨.

#### (B) analytics/feedback.py: HTTP ì—ëŸ¬ì™€ íŒŒì‹± ì—ëŸ¬ ë¯¸ë¶„ë¦¬

```python
resp = requests.post(...)
resp.raise_for_status()
raw = resp.json().get("response", "").strip()
# JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì–´ë””ì„œ ì¡íˆëŠ”ì§€ ë¶ˆëª…í™•
```

#### (C) ì¬ì‹œë„ ë¡œì§ ë¶€ì¬

í¬ë¡¤ëŸ¬ì˜ HTTP ìš”ì²­, Ollama í˜¸ì¶œ ë“±ì— ì¬ì‹œë„(retry) ë¡œì§ì´ ì—†ë‹¤.
ì¼ì‹œì  ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ì—ë„ í•´ë‹¹ ê²Œì‹œê¸€ì„ ì˜êµ¬ ìŠ¤í‚µ.

### í•´ê²°

#### 12-1. BaseCrawlerì— ì¬ì‹œë„ ë°ì½”ë ˆì´í„° ì¶”ê°€

```python
# crawlers/base.pyì— ì¶”ê°€

import time
from functools import wraps
from typing import TypeVar, Callable

T = TypeVar("T")


def retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: tuple = (requests.RequestException,),
) -> Callable:
    """HTTP ìš”ì²­ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°.

    Args:
        max_attempts: ìµœëŒ€ ì‹œë„ íšŸìˆ˜
        delay: ì²« ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        backoff: ëŒ€ê¸° ì‹œê°„ ë°°ìˆ˜
        exceptions: ì¬ì‹œë„í•  ì˜ˆì™¸ íƒ€ì…
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            current_delay = delay
            last_exception = None
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_attempts:
                        log.warning(
                            "%s ì¬ì‹œë„ %d/%d (%.1fì´ˆ í›„): %s",
                            func.__name__, attempt, max_attempts,
                            current_delay, e,
                        )
                        time.sleep(current_delay)
                        current_delay *= backoff
            raise last_exception  # type: ignore[misc]
        return wrapper
    return decorator
```

#### 12-2. `_get()`ê³¼ `_post()`ì— ì¬ì‹œë„ ì ìš©

```python
class BaseCrawler(ABC):
    ...

    @retry(max_attempts=3, delay=1.0)
    def _get(self, url: str, **kwargs) -> requests.Response:
        self._rotate_ua()
        kwargs.setdefault("timeout", REQUEST_TIMEOUT)
        resp = self._session.get(url, **kwargs)
        resp.raise_for_status()
        return resp

    @retry(max_attempts=3, delay=1.0)
    def _post(self, url: str, **kwargs) -> requests.Response:
        self._rotate_ua()
        kwargs.setdefault("timeout", REQUEST_TIMEOUT)
        resp = self._session.post(url, **kwargs)
        resp.raise_for_status()
        return resp
```

#### 12-3. í¬ë¡¤ëŸ¬ì˜ except ì„¸ë¶„í™” (ì„ íƒ)

ê° í¬ë¡¤ëŸ¬ì˜ `parse_post()`ì—ì„œ ì¡ëŠ” ì˜ˆì™¸ë¥¼ ì„¸ë¶„í™”í•  ìˆ˜ ìˆë‹¤.
ë‹¨, í˜„ì¬ `BaseCrawler.run()`ì´ ê°œë³„ ê²Œì‹œê¸€ ì‹¤íŒ¨ë¥¼ ì¡ì•„ì„œ ê³„ì† ì§„í–‰í•˜ëŠ” êµ¬ì¡°ê°€ ì´ë¯¸ ì•ˆì „í•˜ë¯€ë¡œ, **ì´ ì‘ì—…ì€ ì„ íƒì‚¬í•­**ì´ë‹¤.

ë³€ê²½í•œë‹¤ë©´:

```python
# Before
except Exception:
    log.exception(...)

# After
except requests.RequestException:
    log.warning("ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬: %s", item["url"])
    continue
except (AttributeError, ValueError) as e:
    log.warning("íŒŒì‹± ì—ëŸ¬: %s â€” %s", item["url"], e)
    continue
except Exception:
    log.exception("ì˜ˆê¸°ì¹˜ ëª»í•œ ì—ëŸ¬: %s", item["url"])
    continue
```

---

## Task ìˆœì„œ ë° ì˜ì¡´ê´€ê³„

```
Task 6 (ìˆœí™˜ import) â”€â”€â”€â”€ ë…ë¦½, ì¦‰ì‹œ ê°€ëŠ¥
Task 7 (settings ë¶„ë¦¬) â”€â”€ ë…ë¦½, ì¦‰ì‹œ ê°€ëŠ¥
Task 8 (analytics)  â”€â”€â”€â”€â”€ Task 6 ì´í›„ (ScriptData ê²½ë¡œ ë³€ê²½ ì˜í–¥)
Task 9 (plugin_manager) â”€ Task 1 ì™„ë£Œ í›„ (Dead code ì œê±° í›„)
Task 10 (arch/ ì •ë¦¬) â”€â”€â”€â”€ ë…ë¦½, ì¦‰ì‹œ ê°€ëŠ¥
Task 11 (Uploader) â”€â”€â”€â”€â”€â”€ ë…ë¦½, ì¦‰ì‹œ ê°€ëŠ¥
Task 12 (ì—ëŸ¬ ì²˜ë¦¬) â”€â”€â”€â”€â”€ Task 2 ì™„ë£Œ í›„ (BaseCrawler ìˆ˜ì • í›„)
```

**ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ:**
```
Task 6 â†’ Task 8 â†’ Task 7 â†’ Task 9 â†’ Task 10 â†’ Task 11 â†’ Task 12
```

---

## ê²€ì¦ (ì „ì²´)

```bash
# ìˆœí™˜ import ì—†ëŠ”ì§€ í™•ì¸
python -c "from db.models import ScriptData; print('ScriptData in db.models OK')"
python -c "from ai_worker.llm import ScriptData; print('ScriptData re-export OK')"

# settings ì„œë¸Œëª¨ë“ˆ
python -c "from config.crawler import USER_AGENTS; print('crawler config OK')"
python -c "from config.monitoring import MONITORING_ENABLED; print('monitoring config OK')"
python -c "from config.settings import USER_AGENTS; print('re-export OK')"

# analytics
python -c "from analytics.feedback import generate_structured_insights; print('feedback OK')"

# plugin_manager
python -c "from crawlers.plugin_manager import CrawlerRegistry; print('registry OK')"
python -c "
from crawlers.plugin_manager import CrawlerRegistry
assert not hasattr(CrawlerRegistry, 'auto_discover'), 'auto_discover ì•„ì§ ë‚¨ì•„ìˆìŒ'
print('plugin_manager ë‹¨ìˆœí™” OK')
"

# uploader registry
python -c "from uploaders.base import UploaderRegistry; print('UploaderRegistry OK')"

# arch/ êµ¬ì¡°
test -d arch/done && echo "arch/done ì¡´ì¬ OK" || echo "FAIL"
```

---

## ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€ (CLAUDE.md ì¤€ìˆ˜)

| ëŒ€ìƒ | ì´ìœ  |
|---|---|
| `db/models.py`ì˜ ê¸°ì¡´ ëª¨ë¸ ì»¬ëŸ¼ | ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš” (ScriptData í´ë˜ìŠ¤ ì¶”ê°€ëŠ” ì»¬ëŸ¼ ë³€ê²½ì´ ì•„ë‹ˆë¯€ë¡œ í—ˆìš©) |
| `.env` | ì‹œí¬ë¦¿ í¬í•¨ |
| `docker-compose.yml` / `docker-compose.galaxybook.yml` | GPU ë§¤í•‘ ë¯¼ê° |
| `requirements.txt` | ì˜ì¡´ì„± ì¶©ëŒ ìœ„í—˜ |

---

## ë³€ê²½ íŒŒì¼ ìš”ì•½

| íŒŒì¼ | Task | ì‘ì—… |
|---|:---:|---|
| `db/models.py` | 6 | âœï¸ ScriptData í´ë˜ìŠ¤ ì¶”ê°€ (ì»¬ëŸ¼ ë³€ê²½ ì•„ë‹˜) |
| `ai_worker/llm.py` | 6,8 | âœï¸ ScriptData ì œê±° + re-export, `call_ollama_raw()` ì¶”ê°€ |
| `analytics/feedback.py` | 8 | âœï¸ ì§ì ‘ HTTP í˜¸ì¶œ â†’ `call_ollama_raw()` êµì²´ |
| `config/settings.py` | 7 | âœï¸ ë„ë©”ì¸ë³„ ì½”ë“œë¥¼ ì„œë¸Œëª¨ë“ˆë¡œ ì´ë™ + re-export |
| `config/crawler.py` | 7 | ğŸ†• í¬ë¡¤ëŸ¬ ê³µí†µ ì„¤ì • |
| `config/monitoring.py` | 7 | ğŸ†• ëª¨ë‹ˆí„°ë§ ì„¤ì • |
| `crawlers/plugin_manager.py` | 9 | âœï¸ ë¶ˆí•„ìš” ë©”ì„œë“œ ì‚­ì œ |
| `arch/done/` | 10 | ğŸ†• ë””ë ‰í† ë¦¬ ìƒì„± + ì™„ë£Œ ë¬¸ì„œ ì´ë™ |
| `arch/4,5,ai_worker_restructure.md` | 10 | âœï¸ ìƒíƒœ ë°°ë„ˆ ì¶”ê°€ |
| `CLAUDE.md` | 10 | âœï¸ arch/ ê°€ì´ë“œ ì¶”ê°€ |
| `uploaders/base.py` | 11 | âœï¸ UploaderRegistry ì¶”ê°€ |
| `uploaders/youtube.py` | 11 | âœï¸ `@UploaderRegistry.register` ì ìš© |
| `uploaders/uploader.py` | 11 | âœï¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ë°˜ìœ¼ë¡œ êµì²´ |
| `uploaders/ADDING_UPLOADER.md` | 11 | ğŸ†• ì—…ë¡œë” ì¶”ê°€ ê°€ì´ë“œ |
| `crawlers/base.py` | 12 | âœï¸ `retry()` ë°ì½”ë ˆì´í„° ì¶”ê°€ |
