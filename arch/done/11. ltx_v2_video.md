# LTX-Video v2 파이프라인 구현 완료 보고서

> **상태:** 완료 (2026-02-28 ~ 2026-03-01)
> **범위:** LTX-Video v1 도입 → v2(19B) 전면 마이그레이션 → ComfyUI 최적화
> **GPU:** RTX 3090 24GB (Ampere)

---

## 1. 프로젝트 개요

WaggleBot 파이프라인에 AI 비디오 생성 기능을 추가하여, 커뮤니티 게시글을 정적 이미지+TTS 기반 쇼츠가 아닌 **동영상 클립 기반 쇼츠**로 전환하는 작업.

### 1-1. 진행 타임라인

| 단계 | 기간 | 내용 |
|------|------|------|
| Part 1 | 02-28 | LTX-Video v1(2B) 코어 모듈 설계: video/, comfy_client, prompt_engine, image_filter, video_utils |
| Part 2 | 02-28 | 파이프라인 통합(Phase 6~7), 렌더러 확장(하이브리드 합성), 테스트 명세 |
| E2E 테스트 | 02-28 | post_id=903 대상 7단계 E2E 테스트 설계 |
| ComfyUI 환경 | 02-28 | Dockerfile.comfyui 작성, Docker 이미지 빌드, 모델 다운로드 |
| 버그 분석 | 02-28 | I2V 워크플로우 1프레임 버그, 프롬프트 품질 문제 발견 |
| GPU 업그레이드 | 02-28 | RTX 3080 Ti(12GB) → RTX 3090(24GB) 전환, 2막 VRAM 구조 설계 |
| v2 마이그레이션 | 03-01 | LTX-Video 2B 완전 삭제, LTX-2 19B FP8로 전면 교체 |
| FP8 핫픽스 | 03-01 | FP4→FP8 모델 전환, VRAM 관리 최적화 |
| 성능 분석 | 03-01 | comfy_kitchen 비활성/Flash Attention 미설치 병목 식별 |
| 최종 테스트 | 03-01 | Distilled T2V 최소 동작 확인, 환경 복구 |

### 1-2. 최종 상태

- **v1(2B) 레거시**: 완전 삭제 (워크플로우, 모델, 스크립트 모두 제거)
- **v2(19B)**: FP8 모델 기반 운영, Distilled(8스텝) 기본
- **오디오**: Fish Speech TTS 별도 사용 (LTX-2 내장 오디오 노드 제거 — 성능 최적화)
- **워크플로우**: 4종 (t2v, i2v, distilled, upscale)

---

## 2. 아키텍처

### 2-1. 2막 VRAM 전략 (RTX 3090 24GB)

```
1막 (LLM): qwen2.5:14b 8-bit 단독 (~14GB)
   └── 대본/자막/video_prompt 생성
   └── managed_inference 종료 → VRAM 완전 해제

2막 (미디어): Fish Speech (~5GB) + LTX-2 (~12GB weight streaming)
   └── TTS 생성 → VRAM 해제 → 비디오 클립 생성 → VRAM 해제
   └── torch.cuda.empty_cache() + gc.collect() 필수
```

### 2-2. 파이프라인 Phase 순서

```
Phase 1: resource_analyzer    — 이미지:텍스트 비율 분석
Phase 2: llm_chunker          — LLM 의미 단위 청킹
Phase 3: text_validator        — 20자 검증
Phase 4: scene_director        — 씬 배분 + 감정 태그
Phase 4.5: assign_video_modes  — video_mode 할당 (I2V/T2V)
Phase 5: TTS 생성              — Fish Speech
Phase 6: video_prompt 생성     — prompt_engine (GPU 불필요)
Phase 7: video_clip 생성       — ComfyUI + LTX-2 (GPU)
Phase 8: FFmpeg 렌더링          — layout.py 하이브리드 합성
```

### 2-3. OOM 폴백 전략 (4단계)

| 시도 | 해상도 | 프레임 | 스텝 | 워크플로우 |
|------|--------|--------|------|-----------|
| 1차 | 1280x720 | 97 | 20 | t2v_ltx2.json |
| 2차 (프롬프트 단순화) | 1280x720 | 97 | 20 | t2v_ltx2.json |
| 3차 (해상도 다운) | 768x512 | 65 | 15 | t2v_ltx2.json |
| 4차 (Distilled 폴백) | 768x512 | 65 | 8 | t2v_ltx2_distilled.json |

---

## 3. 구현된 모듈

### 3-1. 비디오 코어 (`ai_worker/video/`)

| 파일 | 역할 |
|------|------|
| `__init__.py` | 패키지 초기화 |
| `comfy_client.py` | ComfyUI HTTP/WebSocket 클라이언트, 워크플로우 로딩/패칭, T2V/I2V 생성 |
| `prompt_engine.py` | 한국어 텍스트 → 영어 비디오 프롬프트 변환 (LLM 경유), 9개 mood 스타일 |
| `manager.py` | 씬별 비디오 생성 오케스트레이션, 4단계 재시도, 실패 씬 삭제/병합 |
| `image_filter.py` | 이미지 I2V 적합성 판별 (해상도/엣지/색분포 기반 스코어링) |
| `video_utils.py` | 클립 리사이즈, 루프/트림, 프레임 규칙(1+8k) 검증 |

### 3-2. 워크플로우 (`comfyui_workflows/`)

| 파일 | 설명 |
|------|------|
| `t2v_ltx2.json` | T2V 풀 모델 (20스텝, 1280x720) |
| `t2v_ltx2_distilled.json` | Distilled (8스텝, CFG=1, 기본 운영용) |
| `i2v_ltx2.json` | I2V (첫 프레임 주입, strength 0.7~0.8) |
| `t2v_ltx2_upscale.json` | 2-Stage 업스케일 (640x360→1280x720, 테스트용) |

### 3-3. LTX-2 노드 체인

```
[Gemma3 TextEncoder] → [CLIPTextEncode(pos/neg)]
         ↓
[LTXVConditioning] ← frame_rate=24
         ↓
[EmptyLTXVLatentVideo] ← width, height, length
         ↓
[LTXVScheduler] → sigmas
         ↓
[SamplerCustomAdvanced] ← model, noise, sampler, sigmas, latent
         ↓
[VAEDecode] → video frames
         ↓
[VHS_VideoCombine] → MP4
```

### 3-4. 설정 (`config/settings.py`)

```python
VIDEO_GEN_ENABLED = False  # 운영 활성화 전까지 비활성
VIDEO_MODEL = "ltx2_distilled"
VIDEO_RESOLUTION = (1280, 720)
VIDEO_RESOLUTION_FALLBACK = (768, 512)
VIDEO_NUM_FRAMES = 97       # 1+8*12 (~4초 @24fps)
VIDEO_FPS = 24
VIDEO_STEPS = 20
VIDEO_STEPS_DISTILLED = 8
VIDEO_CFG = 3.5
VIDEO_CFG_DISTILLED = 1.0
VIDEO_MAX_CLIPS_PER_POST = 8
VIDEO_MAX_RETRY = 4
VIDEO_INCLUDE_AUDIO = True  # LTX-2 오디오 ON/OFF
```

### 3-5. 프롬프트 전략

- **한국 중심**: 현대 한국 배경, 한국인 인물, 한국 거리/카페/사무실
- **사실주의**: 다큐멘터리/뉴스 스타일, 자연광, 실제 장소
- **인물 3단계 Tier**:
  - Tier 1: 미디엄 샷 한국인 (옆모습/뒷모습 선호, CFG 3.0~3.5)
  - Tier 2: 오브젝트/환경 중심 (빈 회의실, 커피잔 등)
  - Tier 3: 귀여운 강아지/고양이 애니메이션
- **네거티브 프롬프트**: 사이버펑크/SF/판타지/애니메이션 억제

---

## 4. 인프라

### 4-1. Dockerfile.comfyui

```dockerfile
FROM nvidia/cuda:12.6.3-runtime-ubuntu22.04
# Python 3.11, ComfyUI, VHS, ComfyUI-LTXVideo
CMD ["python3", "main.py", "--listen", "0.0.0.0", "--lowvram", "--reserve-vram", "2"]
```

- `--lowvram`: 19B 모델을 시스템 RAM으로 오프로드 (weight streaming)
- `--reserve-vram 2`: OOM 방지용 2GB 예약
- Flash Attention: 미설치 (CUDA 12.6 ↔ cu128 wheel 버전 불일치, PyTorch SDPA로 대체)

### 4-2. 모델 파일 구조

```
checkpoints/
├── ltx-2/
│   ├── ltx-2-19b-dev-fp8.safetensors         ← 풀 모델 (~27GB on disk)
│   └── ltx-2-19b-distilled-fp8.safetensors    ← Distilled (~27GB on disk)
├── text_encoders/
│   └── gemma-3-12b-it-qat-q4_0-unquantized/  ← Gemma 3 (5 shards)
├── latent_upscale_models/
│   ├── ltx-2-spatial-upscaler-x2-1.0.safetensors
│   └── ltx-2-temporal-upscaler-x2-1.0.safetensors
└── loras/
    └── ltx-2-19b-distilled-lora-384.safetensors
```

### 4-3. 삭제된 레거시

- `comfyui_workflows/t2v_ltx.json`, `i2v_ltx.json` (v1 워크플로우)
- `checkpoints/ltx-video/` (v1 2B 모델)
- `checkpoints/clip/t5xxl_fp8_e4m3fn.safetensors` (v1 텍스트 인코더)
- `scripts/download_ltx_video.sh` (v1 다운로드 스크립트)

---

## 5. 발견된 문제 및 해결

### 5-1. I2V 워크플로우 1프레임 버그 (v1)

**원인**: v1 I2V에서 `VAEEncode`가 이미지 1장을 2D latent로 인코딩, `EmptyLTXVLatentVideo`에 대응하는 멀티프레임 노드 부재.
**해결**: v2 마이그레이션 시 `LTXVImgToVideoInplace` 노드로 교체.

### 5-2. 프롬프트 품질 (v1)

**원인**: 한국어 텍스트만으로 프롬프트 생성 → 이미지/맥락 무관한 허구 장면.
**해결**: 한국 중심 프롬프트 시스템 V2, 추상/상징 비주얼 → 사실적 한국 장면으로 전환.

### 5-3. FP4 모델 비호환 (v2)

**원인**: NVFP4는 RTX 50시리즈(Blackwell) 전용, RTX 3090(Ampere)에서 소프트웨어 에뮬레이션.
**해결**: FP4 삭제, FP8 모델로 전환.

### 5-4. comfy_kitchen 백엔드 비활성 (v2)

**원인**: ComfyUI의 FP8 최적 커널(comfy_kitchen)이 cu130+ 필요, 현재 환경은 cu128.
**영향**: FP8 연산이 비최적 경로로 폴백, 성능 30~50% 손실.
**현상**: Distilled 8스텝 기준 14~18분/클립 (최적화 환경 대비 7~9배 느림).
**대응**: Dockerfile CUDA 베이스 이미지 12.8+ 업그레이드로 해결 가능 (미적용, 향후 과제).

### 5-5. Flash Attention 미설치 (v2)

**원인**: flash-attn wheel(cu128)과 Dockerfile 베이스(cuda:12.6.3) 버전 불일치.
**해결**: flash-attn 설치 라인 제거, PyTorch 내장 SDPA로 대체. 성능 20~40% 손실 감수.

### 5-6. Audio 노드 불필요 실행 (v2)

**원인**: WaggleBot은 Fish Speech TTS를 사용하므로 LTX-2 내장 오디오 불필요.
**해결**: 워크플로우에서 AudioVAE/AudioLatent 노드 제거하여 15~20% 성능 개선.

---

## 6. 성능 현황

### 6-1. RTX 3090 + `--lowvram` 기준

| 워크플로우 | 해상도 | 프레임 | 예상 시간 |
|-----------|--------|--------|----------|
| Distilled (8스텝) | 720p | 97 (~4초) | 1~2분 (최적화 후) / 14~18분 (현재) |
| Full (20스텝) | 720p | 97 | 3~5분 (최적화 후) |
| Upscale 2-Stage | 360p→720p | 97 | 5~8분 (최적화 후) |

### 6-2. 병목 원인 분석

| 병목 | 영향 | 해결 방법 |
|------|------|----------|
| comfy_kitchen 비활성 | 30~50% 손실 | CUDA 12.8+ 베이스 이미지 |
| Flash Attention 미설치 | 20~40% 손실 | 올바른 wheel 설치 |
| Audio 브랜치 | 15~20% 손실 | 워크플로우에서 제거 (완료) |
| --lowvram weight streaming | 필수 오버헤드 | 24GB VRAM 한계 (불가피) |
| Swap 사용 (RAM 40GB) | 5~15% 손실 | WSL RAM 64GB 확장 |

### 6-3. 최적화 로드맵

```
Step 1: Dockerfile CUDA 12.8 업그레이드 → comfy_kitchen 활성화 (40~50% 단축)
Step 2: Flash Attention 올바른 wheel 설치 (20~30% 추가 단축)
Step 3: WSL RAM 64GB (Swap 제거, 10~15% 추가 단축)
Step 4: --normalvram 전환 테스트 (Audio 제거로 VRAM 여유 생기면 시도)

목표: 14~18분/클립 → 1~3분/클립
```

---

## 7. 하드 제약 (CLAUDE.md 연동)

1. **VRAM 2막 구조 필수**: 1막(LLM 단독) → VRAM 해제 → 2막(미디어)
2. **동시 모델 로드**: 총 VRAM 합계 18GB 이하일 때만 허용 (6GB 안전마진)
3. **GPU 컨텍스트 매니저**: `managed_inference()` 패턴 필수
4. **`torch.cuda.empty_cache()` + `gc.collect()`**: 각 단계 후 필수
5. **FFmpeg**: GPU 환경 `h264_nvenc` 필수, `libx264` 수동 지정 금지
6. **`ai_worker/video/`에서 `ai_worker.tts` import 금지**: 의존성 격리
7. **비디오 생성 실패 시 정적 이미지+TTS 폴백 사용 금지**: 실패 씬 삭제 후 대본 병합
8. **VIDEO_GEN_ENABLED=false**: 기존 정적 렌더링 로직 그대로 작동 보장

---

## 8. 참고 자료

- ComfyUI 공식 LTX-2 문서: https://docs.comfy.org/tutorials/video/ltx/ltx-2
- LTX-2 GitHub: https://github.com/Lightricks/LTX-2
- ComfyUI-LTXVideo 노드: https://github.com/Lightricks/ComfyUI-LTXVideo
- LTX-2 프롬프팅 가이드: https://ltx.video/blog/how-to-prompt-for-ltx-2
- RTX 3090 OOM 이슈: https://github.com/Comfy-Org/ComfyUI/issues/12047
