# Fish Speech 1.5 TTS 교체 — 결정 사항 & 작업 개요

## 결정된 사항 (Claude Code는 아래 결정을 그대로 따를 것)

### 1. 모델 선택: S1 (4B) + FP16 강제
- `fishaudio/fish-speech-1.5` 메인 모델 사용
- **이유**: 유튜브 쇼츠 품질이 최우선. Mini(0.5B)는 표현력 부족.
- **FP16(`--half`) 기본 활성화** → 12GB VRAM 내에서 안정 운영
- OOM 발생 시 자동 fallback 없음 (실패 시 로그 후 작업 skip)

### 2. 실행 방식: HTTP API 서버 (Docker 내부)
- Fish Speech를 `fish-speech` 컨테이너로 분리
- WaggleBot ai_worker가 HTTP로 호출 (`http://fish-speech:8080`)
- **이유**: 기존 Ollama 패턴과 동일한 구조 유지

### 3. 참조 오디오: 기본 Korean 내레이터 1종 고정
- `assets/voices/korean_man_default.wav` (10~15초, 깨끗한 남성 내레이터)
- 향후 캐릭터별 추가 가능하도록 `VOICE_PRESET` dict 구조로 관리

### 4. 감정 태그: LLM이 자동 삽입
- hook → `(excited)`, body → 태그 없음(기본), closer → `(friendly)`
- scene_director가 씬 type에 따라 자동 prefix 부착

### 5. 기존 TTS 제거 범위
- Edge-TTS, Kokoro, GPT-SoVITS 중 docker-compose.galaxybook.yml 용으로 가장 가벼운 것 남기기

## 수정 파일 목록
```
docker-compose.yml         ← fish-speech 서비스 추가
ai_worker/tts_worker.py   ← Fish Speech HTTP 클라이언트로 교체
ai_worker/scene_director.py ← 감정 태그 prefix 추가
config/settings.py         ← TTS 관련 상수 추가
assets/voices/             ← korean_narrator.wav 배치
requirements.txt           ← httpx 추가 (aiohttp 대체)
```

# Task 1: docker-compose.yml — fish-speech 서비스 추가

## Claude Code 지시

`docker-compose.yml`에 아래 서비스를 추가하라.
기존 서비스(wagglebot, ollama, db 등)는 **절대 수정하지 말 것**.

```yaml
services:
  fish-speech:
    image: fishaudio/fish-speech:latest
    container_name: fish-speech
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - ./assets/voices:/app/voices:ro   # 참조 오디오 마운트
      - fish_speech_models:/app/checkpoints  # 모델 캐시
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      python -m tools.api_server
      --listen 0.0.0.0:8080
      --checkpoint-path /app/checkpoints/fish-speech-1.5
      --half
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

volumes:
  fish_speech_models:
```

## 확인 사항
- `wagglebot` 서비스의 `depends_on`에 `fish-speech` 추가
- `fish-speech` 컨테이너가 healthy 상태일 때만 wagglebot 시작

```yaml
# wagglebot 서비스 depends_on 수정
depends_on:
  fish-speech:
    condition: service_healthy
  ollama:
    condition: service_started
```

# Task 2: config/settings.py — TTS 상수 추가

## Claude Code 지시

`config/settings.py` 파일 하단에 아래 TTS 설정 블록을 추가하라.
기존 코드는 수정하지 말고 **append** 할 것.

```python
# ────────────────────────────────────────────
# TTS — Fish Speech 1.5
# ────────────────────────────────────────────
FISH_SPEECH_URL = os.getenv("FISH_SPEECH_URL", "http://fish-speech:8080")
FISH_SPEECH_TIMEOUT = 60  # seconds (4B 모델 첫 생성 느림)

# 참조 오디오 프리셋
# key: 씬 용도, value: assets/voices/ 내 파일명
VOICE_PRESETS: dict[str, str] = {
    "default":  "korean_man_default.wav",
    # 향후 추가 예시:
    # "female":   "korean_female.wav",
    # "energetic":"korean_energetic.wav",
}
VOICE_DEFAULT = "default"

# 감정 태그 매핑 (scene type → Fish Speech control tag)
EMOTION_TAGS: dict[str, str] = {
    "intro":    "(excited)",
    "img_text": "",           # 태그 없음 = 자연체
    "text_only":"",
    "outro":    "(friendly)",
}

# 오디오 출력 설정
TTS_OUTPUT_FORMAT = "wav"
TTS_SAMPLE_RATE   = 44100
```
# Task 3: ai_worker/tts_worker.py — Fish Speech 클라이언트 구현

## Claude Code 지시

`ai_worker/tts_worker.py`를 **아래 내용으로 완전히 교체**하라.
Edge-TTS / Kokoro 관련 코드는 모두 제거.

```python
"""Fish Speech 1.5 TTS 클라이언트."""
import asyncio
import logging
from pathlib import Path

import httpx

from config.settings import (
    FISH_SPEECH_URL,
    FISH_SPEECH_TIMEOUT,
    VOICE_PRESETS,
    VOICE_DEFAULT,
    EMOTION_TAGS,
    TTS_OUTPUT_FORMAT,
)

logger = logging.getLogger(__name__)

VOICES_DIR = Path(__file__).parent.parent / "assets" / "voices"


async def synthesize(
    text: str,
    scene_type: str = "img_text",
    voice_key: str = VOICE_DEFAULT,
    output_path: Path | None = None,
) -> Path:
    """
    Fish Speech API로 TTS 생성.

    Args:
        text: 읽을 텍스트
        scene_type: 씬 타입 (감정 태그 자동 결정)
        voice_key: VOICE_PRESETS 키
        output_path: 저장 경로 (None이면 임시파일)
    Returns:
        생성된 wav 파일 경로
    """
    # 감정 태그 prefix 부착
    emotion = EMOTION_TAGS.get(scene_type, "")
    final_text = f"{emotion} {text}".strip() if emotion else text

    # 참조 오디오 경로
    ref_audio = VOICES_DIR / VOICE_PRESETS[voice_key]
    if not ref_audio.exists():
        raise FileNotFoundError(f"참조 오디오 없음: {ref_audio}")

    # 출력 경로
    if output_path is None:
        output_path = Path(f"/tmp/tts_{hash(text)}.{TTS_OUTPUT_FORMAT}")

    async with httpx.AsyncClient(timeout=FISH_SPEECH_TIMEOUT) as client:
        with open(ref_audio, "rb") as f:
            resp = await client.post(
                f"{FISH_SPEECH_URL}/v1/tts",
                data={"text": final_text, "format": TTS_OUTPUT_FORMAT},
                files={"reference_audio": ("ref.wav", f, "audio/wav")},
            )
        resp.raise_for_status()
        output_path.write_bytes(resp.content)
        logger.info(f"TTS 생성 완료: {output_path} ({len(resp.content)//1024}KB)")

    return output_path
```

# Task 4: ai_worker/scene_director.py — 감정 태그 연동

## Claude Code 지시

`SceneDecision` dataclass에 `emotion_tag` 필드를 추가하고,
`SceneDirector.direct()` 메서드에서 씬 타입별로 자동 할당하라.

### SceneDecision 수정
```python
from config.settings import EMOTION_TAGS

@dataclass
class SceneDecision:
    type: Literal["intro", "img_text", "text_only", "outro"]
    text_lines: list[str]
    image_path: Path | None
    text_only_stack: int = 1
    emotion_tag: str = ""   # ← 추가
```

### direct() 메서드 수정
씬을 append하기 전에 emotion_tag를 세팅:
```python
def _make_scene(self, type_: str, lines: list, image=None, stack=1):
    return SceneDecision(
        type=type_,
        text_lines=lines,
        image_path=image,
        text_only_stack=stack,
        emotion_tag=EMOTION_TAGS.get(type_, ""),
    )
```
기존 `SceneDecision(...)` 직접 생성 부분을 모두 `self._make_scene(...)` 으로 교체.

---

## TTS 호출 연동 위치

`content_processor.py`의 파이프라인 마지막에 TTS 루프 추가:

```python
from ai_worker.tts_worker import synthesize

# Phase 5: TTS 생성
for i, scene in enumerate(scenes):
    for j, line in enumerate(scene.text_lines):
        audio_path = await synthesize(
            text=line,
            scene_type=scene.type,
        )
        scene.text_lines[j] = {
            "text": line,
            "audio": str(audio_path),
        }
```

# Task 5: 참조 오디오 & 의존성 정비

## Claude Code 지시

### 5-1. 디렉토리 생성
```bash
mkdir -p assets/voices
```
`assets/voices/README.md` 파일 생성 (내용 아래):
```markdown
# 참조 오디오 (Voice Presets)

Fish Speech 1.5 zero-shot 클로닝용 참조 오디오 파일.

## 요구 사항
- 포맷: WAV, 16kHz 이상, 모노
- 길이: 10~30초 (너무 짧으면 품질 저하)
- 내용: 잡음 없는 깨끗한 음성

## 파일 목록
| 파일명 | 설명 | 용도 |
|---|---|---|
| korean_narrator.wav | 한국어 남성 내레이터 | 기본 (default) |

## 추가 방법
1. wav 파일을 이 디렉토리에 복사
2. config/settings.py 의 VOICE_PRESETS dict에 등록
```

> **korean_narrator.wav는 직접 준비** (녹음 or 다운로드).
> Claude Code는 빈 파일을 만들지 말 것. README만 생성.

---

### 5-2. requirements.txt 수정
아래 패키지를 추가 (중복 시 버전만 확인):
```
httpx>=0.27.0
```
아래 패키지가 있으면 **제거**:
```
edge-tts
kokoro-onnx   # 또는 kokoro 관련 패키지
```

---

### 5-3. 모델 다운로드 스크립트 생성
`scripts/download_fish_speech.sh` 생성:
```bash
#!/bin/bash
# Fish Speech 1.5 모델 다운로드
huggingface-cli download fishaudio/fish-speech-1.5 \
  --local-dir ./checkpoints/fish-speech-1.5
echo "Done. 모델 경로: ./checkpoints/fish-speech-1.5"
```
모델 다운로드가 완료되면 스크립트 삭제

# Task 6: 헬스체크, 에러 핸들링, 테스트

## Claude Code 지시

### 6-1. Fish Speech 서버 헬스체크 유틸
`ai_worker/tts_worker.py` 내 함수 추가:
```python
async def wait_for_fish_speech(retries: int = 10, delay: float = 5.0) -> bool:
    """서버 기동 대기 (컨테이너 시작 직후 호출)."""
    async with httpx.AsyncClient(timeout=5) as client:
        for i in range(retries):
            try:
                r = await client.get(f"{FISH_SPEECH_URL}/health")
                if r.status_code == 200:
                    logger.info("Fish Speech 서버 준비 완료")
                    return True
            except httpx.ConnectError:
                logger.warning(f"Fish Speech 대기중 ({i+1}/{retries})")
                await asyncio.sleep(delay)
    logger.error("Fish Speech 서버 연결 실패")
    return False
```

`main.py` 또는 앱 시작 지점에서 호출:
```python
from ai_worker.tts_worker import wait_for_fish_speech
await wait_for_fish_speech()
```

---

### 6-2. OOM / 에러 처리 원칙
- `httpx.HTTPStatusError` (5xx) → 로그 후 해당 씬 audio=None으로 skip
- 영상 렌더러는 audio=None이면 무음으로 처리 (렌더링 중단 금지)
- **자동 fallback(Mini 모델 등) 없음** — 실패는 명확히 로그

---

### 6-3. 로컬 테스트 스크립트
`test/test_tts.py` 생성:
```python
"""Fish Speech TTS 단독 테스트."""
import asyncio
from ai_worker.tts_worker import synthesize

async def main():
    path = await synthesize(
        text="안녕하세요, Fish Speech 테스트입니다.",
        scene_type="intro",
    )
    print(f"생성 완료: {path}")

asyncio.run(main())
```
실행: `python test/test_tts.py`

---

## 완료 기준 (Definition of Done)
- [ ] `docker compose up fish-speech` 후 `/health` 200 응답
- [ ] `test_tts.py` 실행 시 wav 파일 생성
- [ ] `(excited)` 태그가 intro 씬 텍스트에 붙어 있음
- [ ] OOM 발생 시 해당 씬만 skip하고 파이프라인 계속 진행





