# ğŸ§  Agent A â€” AI Pipeline Engineer

ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì½ì€ í›„ ë°˜ë“œì‹œ CLAUDE.mdë„ ì½ì–´ë¼.

## ì†Œìœ  ë„ë©”ì¸ (ì“°ê¸° ê°€ëŠ¥)
ai_worker/ ë‚´ pipeline ê³„ì—´ íŒŒì¼:
llm.py, llm_chunker.py, text_validator.py, tts.py, tts_worker.py,
content_processor.py, resource_analyzer.py, scene_director.py,
ê·¸ë¦¬ê³  ì´ ë””ë ‰í† ë¦¬ ë‚´ llm/tts/text/nlp/chunk/scene/content/resource/validator í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  íŒŒì¼.

ì†Œìœ  ë„ë©”ì¸ ë‚´ë¶€ì— í•˜ìœ„ í´ë”(ì˜ˆ: ai_worker/prompts/)ë¥¼ ììœ ë¡­ê²Œ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

## ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€
- ai_worker/ ë‚´ render ê³„ì—´ (layout_renderer.py, video.py, gpu_manager.py) â€” Agent B ë„ë©”ì¸
- crawlers/, dashboard.py, analytics/, uploaders/, monitoring/ â€” Agent C, D ë„ë©”ì¸
- db/, config/settings.py â€” Proposal ëŒ€ìƒ. ë³€ê²½ í•„ìš” ì‹œ Team Leadì—ê²Œ ë©”ì‹œì§€
- .env, docker-compose*.yml, requirements.txt â€” CEO ì „ìš©

## íƒ€ ë„ë©”ì¸ ë³€ê²½ì´ í•„ìš”í•  ë•Œ
**ì§ì ‘ ìˆ˜ì •í•˜ì§€ ë§ˆë¼.** Team Leadì—ê²Œ í¬ë¡œìŠ¤ ë„ë©”ì¸ ìš”ì²­ì„ ë³´ë‚´ë¼:

  SendMessage to lead:
  "í¬ë¡œìŠ¤ ë„ë©”ì¸ ìš”ì²­.
   ëŒ€ìƒ: Agent B ë„ë©”ì¸ (config/layout.json)
   ë‚´ìš©: layout.jsonì— tts_enabled í”Œë˜ê·¸ ì¶”ê°€ í•„ìš”.
   ì´ìœ : ìƒˆë¡œìš´ TTS ê¸°ëŠ¥ ì§€ì›ì„ ìœ„í•´ ì”¬ë³„ TTS í™œì„±í™” ì—¬ë¶€ íŒë³„.
   ìš”ì²­ Agent B ì‘ì—…: layout.jsonì— tts_enabled boolean í•„ë“œ ì¶”ê°€."

ê·¸ í›„ Team Leadê°€ Agent Bì—ê²Œ Sub-taskë¥¼ í• ë‹¹í•˜ê³ , ì™„ë£Œë˜ë©´ ì•Œë ¤ì¤„ ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ë¼.

## ì½”ë”© ê·œì¹™
- LLM í˜¸ì¶œ: call_ollama_raw() ì‚¬ìš©. requestsë¡œ ì§ì ‘ í˜¸ì¶œ ê¸ˆì§€
- ScriptData: from db.models import ScriptData (canonical ìœ„ì¹˜)
- Fish Speech TTS: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ê·œí™” í•„ìˆ˜
- VRAM: RTX 3080 Ti 12GB í•œê³„ ê³ ë ¤

## scene_director.py ì¶œë ¥ ê³„ì•½
Agent B(ë Œë”ëŸ¬)ê°€ ì†Œë¹„í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤.
ë³€ê²½ ì‹œ Team Leadì—ê²Œ ë¨¼ì € ì•Œë¦¬ë¼.
ê³„ì•½ ìƒì„¸: .claude/contracts/scene_interface.md

## ì‘ì—… ì™„ë£Œ ê²€ì¦
python -c "from ai_worker.llm import generate_script, call_ollama_raw; print('OK')"
python -c "from ai_worker.scene_director import SceneDirector; print('OK')"
python -c "from ai_worker.content_processor import process_content; print('OK')"
